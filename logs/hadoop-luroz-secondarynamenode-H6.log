2019-09-11 15:49:20,175 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-09-11 15:49:20,189 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-11 15:49:20,508 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-09-11 15:49:20,623 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-11 15:49:20,681 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-11 15:49:20,681 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-11 15:49:20,939 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-09-11 15:49:20,943 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /home/hadoop/hadooptmpdata/dfs/namesecondary does not exist
2019-09-11 15:49:20,944 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /home/hadoop/hadooptmpdata/dfs/namesecondary is in an inconsistent state: checkpoint directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.recoverCreate(SecondaryNameNode.java:998)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:245)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:194)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:690)
2019-09-11 15:49:20,946 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2019-09-11 15:49:20,948 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-09-11 16:14:15,429 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-09-11 16:14:15,441 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-11 16:14:15,759 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-09-11 16:14:15,873 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-11 16:14:15,931 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-11 16:14:15,931 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-11 16:14:16,067 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-09-11 16:14:16,071 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /home/hadoop/hadooptmpdata/dfs/namesecondary does not exist
2019-09-11 16:14:16,072 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /home/hadoop/hadooptmpdata/dfs/namesecondary is in an inconsistent state: checkpoint directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.recoverCreate(SecondaryNameNode.java:998)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:245)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:194)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:690)
2019-09-11 16:14:16,074 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2019-09-11 16:14:16,076 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-09-11 16:59:54,725 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-09-11 16:59:54,736 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-11 16:59:55,055 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-09-11 16:59:55,157 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-11 16:59:55,212 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-11 16:59:55,212 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-11 16:59:55,352 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-09-11 16:59:55,405 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 11897@H6
2019-09-11 16:59:55,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-09-11 16:59:55,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-09-11 16:59:55,425 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-09-11 16:59:55,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-11 16:59:55,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-11 16:59:55,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-11 16:59:55,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 11 16:59:55
2019-09-11 16:59:55,461 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-11 16:59:55,461 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-11 16:59:55,462 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-11 16:59:55,462 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2019-09-11 16:59:55,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-11 16:59:55,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-09-11 16:59:55,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-11 16:59:55,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-11 16:59:55,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-11 16:59:55,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-11 16:59:55,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-11 16:59:55,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-11 16:59:55,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-09-11 16:59:55,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-11 16:59:55,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-11 16:59:55,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-11 16:59:55,485 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-11 16:59:55,532 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-11 16:59:55,532 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-11 16:59:55,532 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-11 16:59:55,532 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-11 16:59:55,533 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-09-11 16:59:55,533 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-09-11 16:59:55,533 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-09-11 16:59:55,589 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-11 16:59:55,589 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-11 16:59:55,589 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-11 16:59:55,589 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2019-09-11 16:59:55,590 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-11 16:59:55,590 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-11 16:59:55,590 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-11 16:59:55,594 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-11 16:59:55,594 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-09-11 16:59:55,594 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-11 16:59:55,604 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-09-11 16:59:55,604 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-11 16:59:55,610 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-09-11 16:59:55,656 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-11 16:59:55,662 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-11 16:59:55,667 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-11 16:59:55,671 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-11 16:59:55,673 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-11 16:59:55,673 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-11 16:59:55,673 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-11 16:59:55,686 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-11 16:59:55,686 INFO org.mortbay.log: jetty-6.1.26
2019-09-11 16:59:55,815 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-09-11 16:59:55,815 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-11 17:00:56,122 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-11 17:00:56,473 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:614487484:1568235506165:CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a&bootstrapstandby=false
2019-09-11 17:00:56,534 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-11 17:00:56,795 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2019-09-11 17:00:56,796 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 322 bytes.
2019-09-11 17:00:56,838 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-63:614487484:1568235506165:CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a
2019-09-11 17:00:56,879 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2019-09-11 17:00:56,879 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000007731785 size 0 bytes.
2019-09-11 17:00:56,937 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-09-11 17:00:56,959 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-11 17:00:56,959 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/luroz/hadoop/checkpoint/current/fsimage_0000000000000000000
2019-09-11 17:00:56,960 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-11 17:00:56,964 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-11 17:00:56,968 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/checkpoint/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2019-09-11 17:00:56,968 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/checkpoint/current/edits_0000000000000000001-0000000000000000002
2019-09-11 17:00:56,985 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/checkpoint/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2019-09-11 17:00:56,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000002 using no compression
2019-09-11 17:00:57,027 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000002 of size 322 bytes saved in 0 seconds.
2019-09-11 17:00:57,072 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /home/luroz/hadoop/checkpoint
2019-09-11 17:00:57,078 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /home/luroz/hadoop/checkpoint
2019-09-11 17:00:57,254 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://localhost:50070 in 0.133 seconds
2019-09-11 17:00:57,254 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 322
2019-09-12 09:25:57,734 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-09-12 09:25:57,768 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-12 09:25:58,096 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-09-12 09:25:58,201 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-12 09:25:58,258 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-12 09:25:58,258 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-12 09:25:58,421 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-09-12 09:25:58,486 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 4621@H6
2019-09-12 09:25:58,504 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-09-12 09:25:58,505 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-09-12 09:25:58,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-09-12 09:25:58,547 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-12 09:25:58,547 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-12 09:25:58,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-12 09:25:58,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 12 09:25:58
2019-09-12 09:25:58,550 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-12 09:25:58,550 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-12 09:25:58,552 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-12 09:25:58,552 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2019-09-12 09:25:58,564 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-12 09:25:58,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-09-12 09:25:58,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-12 09:25:58,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-12 09:25:58,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-12 09:25:58,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-12 09:25:58,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-12 09:25:58,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-12 09:25:58,568 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-09-12 09:25:58,568 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-12 09:25:58,568 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-12 09:25:58,568 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-12 09:25:58,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-12 09:25:58,617 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-12 09:25:58,617 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-12 09:25:58,617 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-12 09:25:58,618 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-12 09:25:58,641 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-09-12 09:25:58,641 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-09-12 09:25:58,641 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-09-12 09:25:58,647 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-12 09:25:58,647 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-12 09:25:58,647 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-12 09:25:58,647 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2019-09-12 09:25:58,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-12 09:25:58,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-12 09:25:58,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-12 09:25:58,651 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-12 09:25:58,651 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-09-12 09:25:58,651 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-12 09:25:58,659 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-09-12 09:25:58,659 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-12 09:25:58,665 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-09-12 09:25:58,712 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-12 09:25:58,718 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 09:25:58,723 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-12 09:25:58,728 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 09:25:58,729 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-12 09:25:58,729 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 09:25:58,729 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 09:25:58,742 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-12 09:25:58,742 INFO org.mortbay.log: jetty-6.1.26
2019-09-12 09:25:58,866 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-09-12 09:25:58,866 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-12 10:07:05,608 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:08:05,826 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:09:05,980 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:10:06,100 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:11:06,234 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:12:06,365 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:13:06,656 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:14:06,920 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:15:07,184 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:16:07,335 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:17:07,486 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:18:07,676 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:19:07,815 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:20:07,955 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:21:08,103 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:22:08,238 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:23:08,455 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:24:08,630 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:25:08,844 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:26:01,517 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-12 10:26:01,519 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-09-12 14:09:18,879 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-09-12 14:09:18,911 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-12 14:09:19,280 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-09-12 14:09:19,396 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-12 14:09:19,464 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-12 14:09:19,464 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-12 14:09:19,737 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-09-12 14:09:19,800 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 17629@H6
2019-09-12 14:09:19,835 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-09-12 14:09:19,836 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-09-12 14:09:19,838 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-09-12 14:09:19,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-12 14:09:19,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-12 14:09:19,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-12 14:09:19,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 12 14:09:19
2019-09-12 14:09:19,880 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-12 14:09:19,880 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-12 14:09:19,881 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-12 14:09:19,881 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2019-09-12 14:09:19,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-12 14:09:19,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-09-12 14:09:19,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-12 14:09:19,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-12 14:09:19,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-12 14:09:19,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-12 14:09:19,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-12 14:09:19,899 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-12 14:09:19,903 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-09-12 14:09:19,903 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-12 14:09:19,903 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-12 14:09:19,903 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-12 14:09:19,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-12 14:09:19,953 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-12 14:09:19,953 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-12 14:09:19,953 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-12 14:09:19,953 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-12 14:09:19,954 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-09-12 14:09:19,954 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-09-12 14:09:19,954 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-09-12 14:09:19,961 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-12 14:09:19,961 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-12 14:09:19,961 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-12 14:09:19,961 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2019-09-12 14:09:19,962 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-12 14:09:19,962 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-12 14:09:19,962 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-12 14:09:19,965 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-12 14:09:19,965 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-09-12 14:09:19,965 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-12 14:09:19,974 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-09-12 14:09:19,974 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-12 14:09:19,980 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-09-12 14:09:20,032 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-12 14:09:20,040 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 14:09:20,057 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-12 14:09:20,063 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 14:09:20,064 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-12 14:09:20,065 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 14:09:20,065 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 14:09:20,078 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-12 14:09:20,078 INFO org.mortbay.log: jetty-6.1.26
2019-09-12 14:09:20,293 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-09-12 14:09:20,293 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-12 14:10:21,605 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:11:21,786 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:12:22,016 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:13:22,225 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:14:22,425 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:15:22,832 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:16:22,952 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:17:23,205 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:18:23,819 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:19:24,209 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:20:25,339 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:21:25,520 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:22:25,627 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:23:25,779 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:24:25,971 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:25:26,279 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:26:26,429 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:27:26,557 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:28:26,698 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:29:26,875 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:30:27,055 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:31:27,173 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:32:27,307 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:33:27,449 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:34:27,654 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:35:28,923 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:36:29,146 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:37:29,268 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:38:29,402 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:39:29,531 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:40:29,702 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:41:29,835 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:42:30,198 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:43:30,401 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:44:30,552 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:45:30,849 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:46:30,982 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:47:31,142 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:48:31,279 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:49:31,377 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:50:31,519 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:51:31,640 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:52:31,815 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:53:32,004 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:54:32,137 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:55:32,367 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:56:32,514 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:57:32,648 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:58:32,879 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 14:59:33,009 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:00:33,464 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:01:33,581 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:02:33,702 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:03:33,835 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:04:34,002 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:05:34,261 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:06:34,378 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:07:34,507 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:08:34,782 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:09:34,940 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:10:35,077 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:11:35,219 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:12:35,349 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:13:35,457 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:14:35,625 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:15:35,844 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:16:35,981 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:17:36,141 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:18:36,275 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:19:36,404 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:20:36,545 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:21:36,671 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:22:36,788 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:23:36,939 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:24:37,066 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:25:37,204 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:26:37,325 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:27:37,518 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:28:37,631 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:29:37,754 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:30:37,942 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:31:38,054 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:32:38,176 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:33:38,399 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:34:38,557 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:35:38,758 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:36:38,862 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:37:38,994 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:38:39,119 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:39:39,364 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:40:39,505 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:41:39,626 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:42:39,755 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:43:39,965 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:44:40,109 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:45:40,208 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:46:40,324 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:47:40,458 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:48:40,579 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:49:40,705 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:50:40,889 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:51:41,008 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:52:41,136 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:53:41,259 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:54:41,378 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:55:41,547 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:56:41,671 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:57:41,807 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:58:41,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 15:59:42,176 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:00:42,412 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:01:42,649 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:02:42,776 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:03:43,040 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:04:43,177 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:05:43,331 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:06:43,486 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:07:43,643 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:08:43,882 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:09:44,028 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:10:44,334 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:11:44,570 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:12:44,700 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:13:44,826 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:14:44,952 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:15:45,172 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:16:45,293 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:17:45,429 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:18:45,648 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:19:45,813 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:20:46,048 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:21:46,262 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:22:46,368 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:23:46,500 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:24:46,637 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:25:46,772 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:26:46,898 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:27:47,025 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:28:47,200 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:29:47,335 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:30:47,537 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:31:47,668 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:32:47,824 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:33:47,949 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:34:48,073 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:35:48,224 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:36:48,350 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:37:48,465 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:38:48,620 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:39:48,741 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:40:48,890 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:41:49,023 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:42:49,203 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:43:49,326 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:44:49,463 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:45:49,701 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:46:49,833 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:47:49,980 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:48:50,111 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:49:50,242 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:50:50,380 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:51:50,510 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:52:50,645 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:53:50,766 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:54:50,877 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:55:51,087 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:56:51,308 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:57:51,439 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:58:51,741 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 16:59:51,855 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:00:52,009 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:01:52,183 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:02:52,312 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:03:52,439 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:04:52,684 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:05:52,825 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:06:52,963 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:07:53,080 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:08:53,231 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:09:53,359 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:10:53,549 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:11:53,702 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:12:53,834 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:13:53,961 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:14:54,091 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:15:54,273 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:16:54,402 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:17:54,638 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:18:54,769 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:19:54,916 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:20:55,052 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:21:55,218 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:22:55,343 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:23:55,500 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:24:55,630 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:25:55,768 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:26:55,897 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:27:56,027 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:28:56,176 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:29:56,304 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:30:56,455 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:31:56,586 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:32:56,719 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:33:56,843 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:34:56,978 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:35:57,106 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:36:57,245 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:37:57,359 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:38:57,495 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:39:57,621 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:40:57,787 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:41:57,984 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:42:58,128 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:43:58,345 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:44:58,488 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:45:58,619 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:46:58,761 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:47:58,897 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:48:59,017 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:49:59,255 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:50:59,522 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:51:59,661 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:52:59,795 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:53:59,933 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:55:00,184 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:56:00,413 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:57:00,546 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:58:00,682 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 17:59:00,811 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:00:00,974 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:01:01,206 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:02:01,354 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:03:01,569 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:04:01,727 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:05:02,015 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:06:02,221 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:07:02,343 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:08:02,502 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:09:02,615 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:10:02,761 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:11:02,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:12:03,089 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:13:03,245 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:14:03,386 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:15:03,524 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:16:03,675 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:17:03,807 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:18:03,939 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:19:04,063 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:20:04,287 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:21:04,458 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:22:04,592 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:23:04,737 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:24:04,878 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:25:05,018 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:26:05,254 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:27:05,498 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1290032588 cTime = 1568235982744 ; clusterId = CID-4195bb56-32a9-4757-8bb2-3655a6681aa1 ; blockpoolId = BP-942232487-127.0.1.1-1568235982744.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 18:27:56,219 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-12 18:27:56,221 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-09-13 10:45:45,556 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-09-13 10:45:45,614 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-13 10:45:45,951 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-09-13 10:45:46,061 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-13 10:45:46,137 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-13 10:45:46,137 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-13 10:45:46,320 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-09-13 10:45:46,382 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 4483@H6
2019-09-13 10:45:46,416 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-09-13 10:45:46,417 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-09-13 10:45:46,419 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-09-13 10:45:46,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-13 10:45:46,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-13 10:45:46,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-13 10:45:46,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 13 10:45:46
2019-09-13 10:45:46,465 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-13 10:45:46,465 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-13 10:45:46,467 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-13 10:45:46,467 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2019-09-13 10:45:46,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-13 10:45:46,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-09-13 10:45:46,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-13 10:45:46,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-13 10:45:46,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-13 10:45:46,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-13 10:45:46,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-13 10:45:46,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-13 10:45:46,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-09-13 10:45:46,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-13 10:45:46,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-13 10:45:46,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-13 10:45:46,486 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-13 10:45:46,533 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-13 10:45:46,533 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-13 10:45:46,533 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-13 10:45:46,533 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-13 10:45:46,557 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-09-13 10:45:46,557 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-09-13 10:45:46,557 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-09-13 10:45:46,563 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-13 10:45:46,563 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-13 10:45:46,564 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-13 10:45:46,564 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2019-09-13 10:45:46,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-13 10:45:46,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-13 10:45:46,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-13 10:45:46,567 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-13 10:45:46,567 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-09-13 10:45:46,567 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-13 10:45:46,575 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-09-13 10:45:46,576 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-13 10:45:46,582 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-09-13 10:45:46,631 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-13 10:45:46,637 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-13 10:45:46,642 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-13 10:45:46,647 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-13 10:45:46,649 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-13 10:45:46,649 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-13 10:45:46,649 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-13 10:45:46,662 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-13 10:45:46,662 INFO org.mortbay.log: jetty-6.1.26
2019-09-13 10:45:46,785 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-09-13 10:45:46,785 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-13 10:58:27,581 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-13 10:58:27,585 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-09-13 15:49:43,670 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-09-13 15:49:43,762 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-13 15:49:44,110 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-09-13 15:49:44,228 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-13 15:49:44,299 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-13 15:49:44,299 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-13 15:49:44,511 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-09-13 15:49:44,596 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 29845@H6
2019-09-13 15:49:44,637 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-09-13 15:49:44,638 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-09-13 15:49:44,640 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-09-13 15:49:44,690 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-13 15:49:44,690 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-13 15:49:44,691 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-13 15:49:44,692 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 13 15:49:44
2019-09-13 15:49:44,693 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-13 15:49:44,693 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-13 15:49:44,694 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-13 15:49:44,694 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2019-09-13 15:49:44,707 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-13 15:49:44,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-09-13 15:49:44,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-13 15:49:44,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-13 15:49:44,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-13 15:49:44,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-13 15:49:44,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-13 15:49:44,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-13 15:49:44,710 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-09-13 15:49:44,710 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-13 15:49:44,710 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-13 15:49:44,710 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-13 15:49:44,712 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-13 15:49:44,765 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-13 15:49:44,765 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-13 15:49:44,765 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-13 15:49:44,765 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-13 15:49:44,796 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-09-13 15:49:44,796 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-09-13 15:49:44,796 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-09-13 15:49:44,803 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-13 15:49:44,803 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-13 15:49:44,803 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-13 15:49:44,803 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2019-09-13 15:49:44,804 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-13 15:49:44,804 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-13 15:49:44,804 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-13 15:49:44,807 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-13 15:49:44,807 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-09-13 15:49:44,807 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-13 15:49:44,815 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-09-13 15:49:44,815 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-13 15:49:44,822 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-09-13 15:49:44,879 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-13 15:49:44,887 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-13 15:49:44,891 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-13 15:49:44,896 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-13 15:49:44,898 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-13 15:49:44,898 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-13 15:49:44,898 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-13 15:49:44,911 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-13 15:49:44,911 INFO org.mortbay.log: jetty-6.1.26
2019-09-13 15:49:45,057 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-09-13 15:49:45,057 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-13 15:58:46,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:58:47,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:58:48,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:58:49,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:58:50,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:58:51,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:58:52,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:58:53,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:58:54,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:58:55,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:58:55,266 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-13 15:58:55,272 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 22 more
2019-09-13 15:59:56,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:59:57,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:59:58,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 15:59:59,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 16:00:00,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 16:00:01,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-13 16:00:02,219 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-13 16:00:02,225 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-09-13 16:05:20,244 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-09-13 16:05:20,280 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-13 16:05:20,675 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-09-13 16:05:20,791 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-13 16:05:20,850 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-13 16:05:20,850 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-13 16:05:21,093 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-09-13 16:05:21,180 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 12491@H6
2019-09-13 16:05:21,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-09-13 16:05:21,225 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-09-13 16:05:21,228 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-09-13 16:05:21,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-13 16:05:21,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-13 16:05:21,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-13 16:05:21,269 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 13 16:05:21
2019-09-13 16:05:21,272 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-13 16:05:21,272 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-13 16:05:21,286 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-13 16:05:21,286 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2019-09-13 16:05:21,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-13 16:05:21,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-09-13 16:05:21,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-13 16:05:21,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-13 16:05:21,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-13 16:05:21,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-13 16:05:21,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-13 16:05:21,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-13 16:05:21,304 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-09-13 16:05:21,304 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-13 16:05:21,305 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-13 16:05:21,305 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-13 16:05:21,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-13 16:05:21,373 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-13 16:05:21,373 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-13 16:05:21,374 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-13 16:05:21,374 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-13 16:05:21,375 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-09-13 16:05:21,375 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-09-13 16:05:21,375 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-09-13 16:05:21,463 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-13 16:05:21,463 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2019-09-13 16:05:21,464 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-13 16:05:21,464 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2019-09-13 16:05:21,465 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-13 16:05:21,465 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-13 16:05:21,465 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-13 16:05:21,468 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-13 16:05:21,468 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-09-13 16:05:21,468 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-13 16:05:21,491 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-09-13 16:05:21,491 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-13 16:05:21,498 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-09-13 16:05:21,553 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-13 16:05:21,559 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-13 16:05:21,564 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-13 16:05:21,570 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-13 16:05:21,572 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-13 16:05:21,572 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-13 16:05:21,572 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-13 16:05:21,587 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-13 16:05:21,587 INFO org.mortbay.log: jetty-6.1.26
2019-09-13 16:05:21,750 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-09-13 16:05:21,750 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-16 14:24:34,892 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-09-16 14:24:34,941 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-16 14:24:35,285 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-09-16 14:24:35,393 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-16 14:24:35,448 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-16 14:24:35,448 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-16 14:24:35,613 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-16 14:24:35,614 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-16 14:24:35,673 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-09-16 14:24:35,766 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 9867@H6
2019-09-16 14:24:35,798 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-09-16 14:24:35,799 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-09-16 14:24:35,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-09-16 14:24:35,829 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-16 14:24:35,829 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-16 14:24:35,831 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-16 14:24:35,831 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 16 14:24:35
2019-09-16 14:24:35,832 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-16 14:24:35,832 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-16 14:24:35,833 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-16 14:24:35,833 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-16 14:24:35,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-16 14:24:35,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-16 14:24:35,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-16 14:24:35,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-16 14:24:35,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-16 14:24:35,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-16 14:24:35,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-16 14:24:35,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-16 14:24:35,850 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-09-16 14:24:35,850 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-16 14:24:35,850 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-16 14:24:35,850 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-16 14:24:35,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-16 14:24:35,902 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-16 14:24:35,902 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-16 14:24:35,902 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-16 14:24:35,902 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-16 14:24:35,904 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-09-16 14:24:35,904 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-09-16 14:24:35,905 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-09-16 14:24:35,911 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-16 14:24:35,911 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-16 14:24:35,911 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-16 14:24:35,911 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-16 14:24:35,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-16 14:24:35,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-16 14:24:35,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-16 14:24:35,915 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-16 14:24:35,915 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-09-16 14:24:35,915 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-16 14:24:35,940 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-09-16 14:24:35,940 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-16 14:24:35,946 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-09-16 14:24:35,990 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-16 14:24:35,997 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-16 14:24:36,001 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-16 14:24:36,006 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-16 14:24:36,008 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-16 14:24:36,008 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-16 14:24:36,008 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-16 14:24:36,019 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-16 14:24:36,019 INFO org.mortbay.log: jetty-6.1.26
2019-09-16 14:24:36,213 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-09-16 14:24:36,213 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-16 14:25:36,484 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:26:28,705 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-16 14:26:28,710 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-09-16 14:26:58,194 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-09-16 14:26:58,201 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-16 14:26:58,541 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-09-16 14:26:58,646 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-16 14:26:58,702 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-16 14:26:58,702 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-16 14:26:58,804 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-16 14:26:58,804 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-16 14:26:58,842 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-09-16 14:26:58,890 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 11204@H6
2019-09-16 14:26:58,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-09-16 14:26:58,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-09-16 14:26:58,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-09-16 14:26:58,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-16 14:26:58,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-16 14:26:58,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-16 14:26:58,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 16 14:26:58
2019-09-16 14:26:58,944 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-16 14:26:58,944 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-16 14:26:58,945 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-16 14:26:58,945 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-16 14:26:58,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-16 14:26:58,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-16 14:26:58,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-16 14:26:58,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-16 14:26:58,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-16 14:26:58,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-16 14:26:58,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-16 14:26:58,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-16 14:26:58,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-09-16 14:26:58,962 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-16 14:26:58,962 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-16 14:26:58,962 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-16 14:26:58,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-16 14:26:59,015 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-16 14:26:59,015 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-16 14:26:59,016 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-16 14:26:59,016 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-16 14:26:59,018 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-09-16 14:26:59,018 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-09-16 14:26:59,018 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-09-16 14:26:59,026 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-16 14:26:59,026 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-16 14:26:59,026 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-16 14:26:59,026 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-16 14:26:59,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-16 14:26:59,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-16 14:26:59,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-16 14:26:59,031 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-16 14:26:59,031 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-09-16 14:26:59,031 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-16 14:26:59,058 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-09-16 14:26:59,058 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-16 14:26:59,065 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-09-16 14:26:59,115 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-16 14:26:59,121 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-16 14:26:59,131 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-16 14:26:59,137 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-16 14:26:59,140 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-16 14:26:59,140 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-16 14:26:59,140 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-16 14:26:59,152 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-16 14:26:59,152 INFO org.mortbay.log: jetty-6.1.26
2019-09-16 14:26:59,243 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-09-16 14:26:59,243 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-16 14:27:59,672 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:28:59,880 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:30:00,047 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:31:00,225 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:32:00,404 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:33:00,624 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:34:00,802 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:35:00,997 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:36:01,175 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:37:01,322 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:38:01,510 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:39:01,783 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:40:01,960 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:41:02,114 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:42:02,291 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:43:02,543 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:44:02,712 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:45:02,867 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:46:03,048 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:47:03,202 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:48:03,408 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:49:03,538 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:50:03,711 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:51:03,879 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:52:04,024 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:53:04,213 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:54:04,390 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:55:04,562 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:56:04,734 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:57:04,883 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:58:05,050 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 14:59:05,275 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:00:05,470 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:01:05,640 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:02:05,793 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:03:05,956 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:04:06,126 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:05:06,531 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:06:06,713 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:07:06,911 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:08:07,081 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:09:07,206 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:10:07,370 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:11:07,519 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:12:07,677 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:13:07,816 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:14:08,039 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:15:08,192 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:16:08,357 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:17:08,523 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:18:08,706 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:19:08,870 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:20:09,030 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:21:09,187 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:22:09,362 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:23:09,498 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:24:09,656 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:25:09,779 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:26:09,914 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:27:10,079 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:28:10,229 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:29:10,396 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:30:10,511 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:31:10,686 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:32:10,827 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:33:11,009 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:34:11,198 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:35:11,380 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:36:11,538 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:37:11,713 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:38:11,862 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:39:12,038 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:40:12,312 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:41:12,478 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:42:12,654 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:43:12,866 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:44:13,040 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:45:13,221 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:46:13,383 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:47:13,546 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:48:13,727 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:49:13,879 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:50:14,066 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:51:14,256 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:52:14,424 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:53:14,631 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:54:14,822 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:55:14,984 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:56:15,250 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:57:15,436 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:58:15,632 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 15:59:15,777 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:00:15,947 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:01:16,129 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:02:16,321 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:03:16,734 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:04:16,909 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:05:17,093 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:06:17,255 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:07:17,421 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:08:17,613 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:09:17,801 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:10:17,959 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:11:18,135 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-16 16:12:17,708 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-16 16:12:17,709 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-09-18 14:49:24,856 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-09-18 14:49:24,894 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-18 14:49:25,272 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-09-18 14:49:25,377 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-18 14:49:25,433 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-18 14:49:25,433 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-18 14:49:25,656 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-18 14:49:25,656 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-18 14:49:25,714 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-09-18 14:49:25,791 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 17453@H6
2019-09-18 14:49:25,837 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-09-18 14:49:25,838 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-09-18 14:49:25,840 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-09-18 14:49:25,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-18 14:49:25,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-18 14:49:25,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-18 14:49:25,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 18 14:49:25
2019-09-18 14:49:25,872 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-18 14:49:25,872 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-18 14:49:25,873 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-18 14:49:25,873 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-18 14:49:25,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-18 14:49:25,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-18 14:49:25,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-18 14:49:25,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-18 14:49:25,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-18 14:49:25,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-18 14:49:25,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-18 14:49:25,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-18 14:49:25,889 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-09-18 14:49:25,889 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-18 14:49:25,889 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-18 14:49:25,889 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-18 14:49:25,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-18 14:49:25,941 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-18 14:49:25,941 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-18 14:49:25,941 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-18 14:49:25,941 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-18 14:49:25,943 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-09-18 14:49:25,943 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-09-18 14:49:25,943 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-09-18 14:49:25,949 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-18 14:49:25,949 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-18 14:49:25,949 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-18 14:49:25,949 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-18 14:49:25,950 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-18 14:49:25,950 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-18 14:49:25,950 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-18 14:49:25,953 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-18 14:49:25,953 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-09-18 14:49:25,953 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-18 14:49:25,984 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-09-18 14:49:25,984 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-18 14:49:25,990 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-09-18 14:49:26,034 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-18 14:49:26,041 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-18 14:49:26,045 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-18 14:49:26,049 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-18 14:49:26,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-18 14:49:26,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-18 14:49:26,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-18 14:49:26,062 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-18 14:49:26,062 INFO org.mortbay.log: jetty-6.1.26
2019-09-18 14:49:26,221 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-09-18 14:49:26,221 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-18 14:50:26,436 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 14:51:26,600 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 14:52:26,722 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 14:53:26,828 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 14:54:26,971 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 14:55:27,134 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 14:56:27,344 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 14:57:27,441 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 14:58:27,558 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 14:59:27,682 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:00:27,806 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:01:27,912 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:02:28,025 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:03:28,134 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:04:28,241 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:05:28,365 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:06:28,484 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:07:28,601 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:08:28,705 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:09:28,821 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:10:28,948 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:11:29,054 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:12:29,161 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:13:29,270 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:14:29,388 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:15:29,513 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:16:29,668 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:17:29,767 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-09-18 15:18:23,235 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-18 15:18:23,248 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-02 07:54:57,877 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-02 07:54:57,915 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-02 07:54:58,268 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-02 07:54:58,373 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-02 07:54:58,426 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-02 07:54:58,426 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-02 07:54:59,610 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-02 07:54:59,610 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-02 07:54:59,652 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-02 07:54:59,896 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 6537@H6
2019-10-02 07:54:59,979 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-02 07:54:59,980 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-02 07:54:59,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-02 07:55:00,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-02 07:55:00,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-02 07:55:00,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-02 07:55:00,013 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 02 07:55:00
2019-10-02 07:55:00,014 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-02 07:55:00,014 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-02 07:55:00,015 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-02 07:55:00,015 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-02 07:55:00,027 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-02 07:55:00,029 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-02 07:55:00,029 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-02 07:55:00,029 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-02 07:55:00,029 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-02 07:55:00,029 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-02 07:55:00,029 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-02 07:55:00,029 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-02 07:55:00,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-02 07:55:00,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-02 07:55:00,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-02 07:55:00,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-02 07:55:00,033 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-02 07:55:00,084 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-02 07:55:00,084 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-02 07:55:00,084 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-02 07:55:00,085 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-02 07:55:00,086 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-02 07:55:00,086 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-02 07:55:00,087 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-02 07:55:00,093 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-02 07:55:00,093 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-02 07:55:00,093 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-02 07:55:00,093 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-02 07:55:00,094 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-02 07:55:00,094 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-02 07:55:00,094 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-02 07:55:00,097 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-02 07:55:00,097 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-02 07:55:00,097 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-02 07:55:00,138 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-02 07:55:00,138 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-02 07:55:00,144 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-02 07:55:00,192 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-02 07:55:00,199 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-02 07:55:00,210 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-02 07:55:00,214 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-02 07:55:00,216 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-02 07:55:00,216 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-02 07:55:00,217 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-02 07:55:00,228 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-02 07:55:00,229 INFO org.mortbay.log: jetty-6.1.26
2019-10-02 07:55:00,351 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-02 07:55:00,351 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-02 08:44:01,735 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:45:02,189 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:46:02,367 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:47:02,510 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:48:02,660 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:49:02,862 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:50:03,047 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:51:03,236 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:52:03,454 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:53:03,620 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:54:03,801 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:55:03,938 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:56:04,105 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:57:04,266 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:58:04,446 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 08:59:04,622 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:00:04,891 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:01:05,034 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:02:05,251 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:03:05,416 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:04:05,649 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:05:05,820 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:06:05,979 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:07:06,125 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:08:06,282 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:09:06,458 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:10:06,600 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:11:06,823 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:12:07,092 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:13:07,243 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:14:07,409 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:15:07,576 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:16:07,743 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:17:07,995 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:18:08,155 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:19:08,323 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:20:08,527 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:21:08,692 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:22:08,896 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:23:09,066 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:24:09,236 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:25:09,457 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:26:09,890 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:27:10,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-02 09:27:11,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-02 09:27:12,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-02 09:27:13,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-02 09:27:14,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-02 09:27:15,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-02 09:27:16,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-02 09:27:17,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-02 09:27:18,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-02 09:27:19,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-02 09:27:19,997 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-02 09:27:20,044 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 21 more
2019-10-02 09:27:44,200 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-02 09:27:44,202 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-03 10:10:23,857 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-03 10:10:23,899 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-03 10:10:24,411 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-03 10:10:24,551 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-03 10:10:24,606 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-03 10:10:24,606 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-03 10:10:26,600 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-03 10:10:26,601 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-03 10:10:26,744 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-03 10:10:26,854 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 9524@H6
2019-10-03 10:10:26,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-03 10:10:26,902 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-03 10:10:26,904 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-03 10:10:26,932 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-03 10:10:26,932 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-03 10:10:26,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-03 10:10:26,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 03 10:10:26
2019-10-03 10:10:26,935 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-03 10:10:26,935 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-03 10:10:26,936 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-03 10:10:26,936 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-03 10:10:26,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-03 10:10:26,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-03 10:10:26,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-03 10:10:26,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-03 10:10:26,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-03 10:10:26,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-03 10:10:26,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-03 10:10:26,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-03 10:10:26,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-03 10:10:26,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-03 10:10:26,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-03 10:10:26,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-03 10:10:26,954 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-03 10:10:27,004 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-03 10:10:27,004 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-03 10:10:27,004 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-03 10:10:27,004 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-03 10:10:27,006 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-03 10:10:27,006 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-03 10:10:27,006 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-03 10:10:27,013 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-03 10:10:27,013 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-03 10:10:27,013 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-03 10:10:27,013 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-03 10:10:27,015 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-03 10:10:27,015 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-03 10:10:27,015 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-03 10:10:27,019 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-03 10:10:27,019 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-03 10:10:27,019 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-03 10:10:27,362 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-03 10:10:27,363 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-03 10:10:27,369 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-03 10:10:27,669 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-03 10:10:27,675 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-03 10:10:27,680 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-03 10:10:27,691 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-03 10:10:27,692 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-03 10:10:27,693 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-03 10:10:27,693 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-03 10:10:27,718 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-03 10:10:27,718 INFO org.mortbay.log: jetty-6.1.26
2019-10-03 10:10:28,045 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-03 10:10:28,057 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-03 10:36:42,839 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:37:43,175 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:38:43,366 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:39:43,558 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:40:43,718 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:41:43,867 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:42:44,011 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:43:44,151 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:44:44,429 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:45:44,618 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:46:44,813 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:47:44,965 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:48:45,169 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:49:45,342 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:50:45,498 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:51:45,767 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:52:46,011 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:53:46,254 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:54:46,461 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 10:55:46,635 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        2019-10-03 11:06:05,200 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-03 11:06:05,249 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-03 11:06:05,675 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-03 11:06:05,808 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-03 11:06:05,899 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-03 11:06:05,899 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-03 11:06:06,284 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-03 11:06:06,284 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-03 11:06:06,326 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-03 11:06:06,443 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 4793@H6
2019-10-03 11:06:06,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-03 11:06:06,498 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-03 11:06:06,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-03 11:06:06,532 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-03 11:06:06,532 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-03 11:06:06,533 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-03 11:06:06,533 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 03 11:06:06
2019-10-03 11:06:06,535 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-03 11:06:06,535 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-03 11:06:06,536 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-03 11:06:06,536 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-03 11:06:06,553 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-03 11:06:06,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-03 11:06:06,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-03 11:06:06,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-03 11:06:06,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-03 11:06:06,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-03 11:06:06,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-03 11:06:06,556 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-03 11:06:06,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-03 11:06:06,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-03 11:06:06,558 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-03 11:06:06,558 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-03 11:06:06,560 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-03 11:06:06,620 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-03 11:06:06,620 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-03 11:06:06,620 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-03 11:06:06,620 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-03 11:06:06,622 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-03 11:06:06,622 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-03 11:06:06,623 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-03 11:06:06,629 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-03 11:06:06,629 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-03 11:06:06,629 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-03 11:06:06,629 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-03 11:06:06,631 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-03 11:06:06,631 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-03 11:06:06,631 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-03 11:06:06,634 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-03 11:06:06,634 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-03 11:06:06,634 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-03 11:06:06,715 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-03 11:06:06,715 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-03 11:06:06,722 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-03 11:06:06,770 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-03 11:06:06,777 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-03 11:06:06,782 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-03 11:06:06,787 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-03 11:06:06,789 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-03 11:06:06,789 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-03 11:06:06,789 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-03 11:06:06,802 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-03 11:06:06,802 INFO org.mortbay.log: jetty-6.1.26
2019-10-03 11:06:07,041 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-03 11:06:07,041 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-03 12:00:17,368 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 12:01:17,685 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 12:02:18,207 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 12:03:18,458 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 12:04:18,692 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 12:05:18,855 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 12:06:19,039 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 12:07:19,343 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-03 12:08:19,559 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        2019-10-04 09:36:57,858 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-04 09:36:57,903 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-04 09:36:58,396 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-04 09:36:58,501 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-04 09:36:58,555 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 09:36:58,556 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-04 09:36:59,461 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-04 09:36:59,461 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-04 09:36:59,504 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-04 09:36:59,647 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 6367@H6
2019-10-04 09:36:59,698 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-04 09:36:59,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-04 09:36:59,700 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-04 09:36:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-04 09:36:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-04 09:36:59,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-04 09:36:59,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 04 09:36:59
2019-10-04 09:36:59,731 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-04 09:36:59,731 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-04 09:36:59,732 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-04 09:36:59,732 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-04 09:36:59,745 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-04 09:36:59,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-04 09:36:59,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-04 09:36:59,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-04 09:36:59,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-04 09:36:59,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-04 09:36:59,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-04 09:36:59,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-04 09:36:59,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-04 09:36:59,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-04 09:36:59,749 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-04 09:36:59,749 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-04 09:36:59,750 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-04 09:36:59,800 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-04 09:36:59,800 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-04 09:36:59,800 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-04 09:36:59,800 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-04 09:36:59,801 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-04 09:36:59,801 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-04 09:36:59,801 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-04 09:36:59,808 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-04 09:36:59,808 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-04 09:36:59,808 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-04 09:36:59,808 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-04 09:36:59,809 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-04 09:36:59,809 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-04 09:36:59,809 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-04 09:36:59,829 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-04 09:36:59,829 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-04 09:36:59,829 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-04 09:36:59,837 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-04 09:36:59,837 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-04 09:36:59,843 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-04 09:36:59,893 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-04 09:36:59,900 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-04 09:36:59,906 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-04 09:36:59,911 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-04 09:36:59,915 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-04 09:36:59,915 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-04 09:36:59,915 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-04 09:36:59,931 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-04 09:36:59,931 INFO org.mortbay.log: jetty-6.1.26
2019-10-04 09:37:00,130 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-04 09:37:00,130 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-04 10:28:00,897 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:29:01,225 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:30:01,586 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:31:02,073 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:32:03,767 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:33:04,711 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:34:04,963 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:35:05,126 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:36:05,396 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:37:05,544 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:38:05,771 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:39:05,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:40:06,107 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:41:06,393 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:42:06,605 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:43:06,938 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:44:07,151 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:45:07,294 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:46:07,491 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:47:07,638 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:48:07,804 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:49:07,959 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:50:08,143 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:51:08,323 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:52:08,534 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:53:08,756 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:54:08,899 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:55:09,112 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:56:09,321 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:57:09,508 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:58:09,688 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 10:59:09,950 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:00:10,180 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:01:10,372 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:02:10,511 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:03:10,681 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:04:10,846 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:05:11,055 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:06:11,192 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:07:11,438 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:08:11,731 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:09:11,975 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:10:12,153 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:11:12,347 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:12:12,523 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:13:12,723 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:14:12,885 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:15:13,063 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:16:13,263 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:17:13,450 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:18:13,606 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:19:13,776 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:20:13,965 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:21:14,136 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:22:14,314 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:23:14,474 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:24:14,649 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:25:14,810 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:26:14,990 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:27:15,159 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:28:15,303 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:29:15,474 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:30:15,734 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:31:15,912 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:32:16,094 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:33:16,275 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:34:16,447 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:35:16,627 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:36:16,846 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:37:17,017 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:38:17,467 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:39:18,173 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:40:18,515 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:41:18,707 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:42:18,870 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:43:19,101 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:44:19,294 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:45:19,530 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:46:19,671 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:47:19,867 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:48:20,047 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:49:20,340 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:50:20,533 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:51:20,705 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:52:20,881 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:53:21,063 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:54:21,253 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:55:21,515 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:56:21,776 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:57:21,950 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:58:22,171 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 11:59:22,349 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:00:22,514 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:01:22,751 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:02:22,903 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:03:23,153 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:04:23,500 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:05:24,177 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:06:24,510 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:07:24,674 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:08:24,973 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:09:25,133 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:10:25,320 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:11:25,502 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:12:25,659 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:13:25,852 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:14:26,054 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:15:26,233 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:16:26,386 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:17:26,574 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:18:26,748 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:19:26,911 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:20:27,102 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:21:27,251 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:22:27,398 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:23:27,620 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:24:27,815 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:25:28,381 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:26:28,531 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:27:28,821 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:28:29,008 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:29:29,193 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:30:29,360 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:31:29,531 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:32:29,709 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:33:29,962 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:34:30,125 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:35:30,333 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:36:30,555 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:37:30,731 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:38:30,907 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:39:31,089 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:40:31,208 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:41:31,367 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:42:31,512 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:43:31,690 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:44:31,848 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:45:31,998 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:46:32,156 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:47:32,311 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:48:32,462 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:49:32,619 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:50:32,764 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:51:32,919 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:52:33,060 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:53:33,252 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:54:33,414 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:55:33,577 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:56:33,740 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:57:33,917 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:58:34,101 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 12:59:34,269 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:00:34,444 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:01:34,652 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:02:34,827 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:03:34,998 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:04:35,163 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:05:35,328 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:06:35,472 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:07:35,616 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:08:35,810 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:09:35,992 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:10:36,158 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:11:36,334 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:12:36,534 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:13:36,757 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:14:36,910 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:15:37,128 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:16:37,287 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:17:37,484 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:18:37,677 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:19:37,828 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:20:37,973 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:21:38,128 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:22:38,282 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:23:38,457 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:24:38,626 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:25:38,784 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:26:38,926 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:27:39,078 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:28:39,247 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:29:39,381 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:30:39,561 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:31:39,852 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:32:40,031 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:33:40,209 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:34:40,397 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:35:40,624 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:36:40,797 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:37:40,977 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:38:41,249 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:39:41,417 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:40:41,576 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:41:41,726 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:42:42,127 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:43:42,408 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:44:42,552 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:45:42,686 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:46:42,873 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:47:43,022 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:48:43,199 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:49:43,358 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:50:44,009 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:51:44,252 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:52:44,445 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:53:44,626 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:54:44,859 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:55:45,025 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:56:45,196 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:57:45,460 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:58:45,624 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 13:59:45,779 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:00:45,435 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:01:45,603 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:02:45,840 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:03:46,078 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:04:46,374 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:05:46,621 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:06:47,009 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:07:47,277 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:08:47,518 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:09:47,744 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:10:47,992 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:11:48,217 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:12:48,507 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:13:48,722 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:14:48,884 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:15:49,082 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:16:49,338 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:17:49,668 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:18:49,888 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:19:50,174 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:20:50,345 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:21:50,559 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:22:50,749 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:23:50,944 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:24:51,129 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:25:51,293 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:26:51,499 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:27:51,686 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:28:51,906 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:29:51,477 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:30:51,850 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:31:52,603 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:32:52,849 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:33:53,196 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:34:53,378 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:35:53,516 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:36:53,739 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:37:53,883 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:38:54,747 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:39:55,441 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:40:55,777 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:41:56,040 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:42:56,323 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:43:56,731 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:44:56,905 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:45:57,095 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:46:57,357 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:47:57,548 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:48:57,751 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:49:58,141 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:51:08,739 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:52:17,702 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:53:26,609 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:54:29,965 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:55:33,154 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:56:37,046 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:57:39,040 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:58:42,067 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 14:59:47,303 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 15:00:53,723 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 15:01:58,269 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 15:03:00,725 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 15:04:05,460 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 15:05:16,729 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 15:06:21,748 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 15:07:23,139 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-04 15:08:27,695 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-04 15:08:31,332 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-09 10:00:57,628 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-09 10:00:57,690 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-09 10:00:58,018 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-09 10:00:58,120 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-09 10:00:58,178 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-09 10:00:58,178 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-09 10:00:59,317 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-09 10:00:59,318 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-09 10:00:59,425 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-09 10:00:59,525 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 7105@H6
2019-10-09 10:00:59,573 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-09 10:00:59,574 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-09 10:00:59,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-09 10:00:59,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-09 10:00:59,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-09 10:00:59,605 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-09 10:00:59,605 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 09 10:00:59
2019-10-09 10:00:59,606 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-09 10:00:59,606 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-09 10:00:59,607 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-09 10:00:59,607 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-09 10:00:59,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-09 10:00:59,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-09 10:00:59,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-09 10:00:59,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-09 10:00:59,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-09 10:00:59,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-09 10:00:59,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-09 10:00:59,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-09 10:00:59,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-09 10:00:59,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-09 10:00:59,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-09 10:00:59,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-09 10:00:59,625 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-09 10:00:59,676 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-09 10:00:59,676 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-09 10:00:59,676 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-09 10:00:59,676 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-09 10:00:59,678 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-09 10:00:59,678 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-09 10:00:59,678 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-09 10:00:59,684 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-09 10:00:59,684 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-09 10:00:59,684 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-09 10:00:59,684 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-09 10:00:59,686 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-09 10:00:59,686 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-09 10:00:59,686 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-09 10:00:59,689 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-09 10:00:59,689 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-09 10:00:59,689 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-09 10:00:59,834 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-09 10:00:59,834 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-09 10:00:59,842 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-09 10:00:59,888 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-09 10:00:59,894 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-09 10:00:59,898 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-09 10:00:59,903 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-09 10:00:59,904 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-09 10:00:59,904 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-09 10:00:59,905 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-09 10:00:59,916 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-09 10:00:59,916 INFO org.mortbay.log: jetty-6.1.26
2019-10-09 10:01:00,114 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-09 10:01:00,114 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-09 10:08:00,567 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:09:00,755 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:10:00,951 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:11:01,123 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:12:01,305 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:13:01,500 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:14:01,689 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:15:01,886 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:16:02,042 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:17:02,248 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:18:02,434 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:19:02,623 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:20:02,797 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:21:02,961 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:22:03,156 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:23:03,354 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:24:03,533 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:25:03,715 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:26:03,898 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:27:04,076 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:28:04,237 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:29:04,413 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:30:04,580 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:31:04,768 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:32:05,020 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:33:05,156 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:34:05,316 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:35:05,501 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:36:05,661 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:37:05,941 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:38:06,144 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:39:06,349 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:40:06,521 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:41:06,772 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:42:06,964 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:43:07,126 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:44:07,366 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:45:07,734 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:46:07,893 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:47:08,088 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:48:08,280 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:49:08,464 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:50:08,649 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:51:08,892 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:52:09,095 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:53:09,286 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:54:09,501 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:55:09,682 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:56:09,881 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:57:10,084 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:58:10,271 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 10:59:10,464 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:00:10,685 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:01:11,078 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:02:11,972 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:03:12,190 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:04:12,385 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:05:12,669 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:06:12,855 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:07:13,114 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:08:13,415 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:09:13,585 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:10:13,749 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:11:13,917 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:12:14,080 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:13:14,331 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:14:14,564 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:15:14,737 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:16:14,906 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:17:15,074 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:18:15,249 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:19:15,401 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:20:15,588 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:21:15,756 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:22:15,984 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:23:16,135 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:24:16,309 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:25:16,474 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:26:16,700 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:27:16,856 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:28:17,023 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:29:17,234 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:30:17,375 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:31:17,545 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:32:17,696 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:33:17,859 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:34:18,012 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:35:18,160 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:36:18,339 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:37:18,571 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:38:18,741 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:39:18,876 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:40:19,026 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:41:19,169 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:42:19,362 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:43:19,603 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:44:19,769 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:45:19,940 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:46:20,120 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:47:20,287 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:48:20,526 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:49:20,701 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:50:20,881 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:51:21,067 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:52:21,218 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:53:21,418 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:54:21,631 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:55:21,788 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:56:21,954 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:57:22,149 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:58:22,292 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 11:59:22,464 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:00:22,636 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:01:22,833 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:02:23,025 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:03:23,170 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:04:23,327 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:05:23,479 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:06:23,629 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:07:23,810 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:08:23,959 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:09:24,140 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:10:24,297 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:11:24,474 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:12:24,652 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:13:24,843 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:14:25,049 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:15:25,273 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:16:25,546 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:17:25,714 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:18:25,861 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:19:26,020 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:20:26,214 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:21:26,394 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:22:26,569 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:23:26,739 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:24:26,905 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:25:27,073 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:26:27,226 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:27:27,393 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:28:27,561 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:29:27,732 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:30:27,882 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:31:28,029 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:32:28,206 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:33:28,354 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:34:28,527 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:35:28,754 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:36:29,058 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:37:29,293 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:38:29,442 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:39:29,629 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:40:29,783 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:41:29,957 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:42:30,141 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:43:30,382 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:44:30,531 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:45:30,695 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:46:30,846 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:47:31,046 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:48:31,536 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:49:31,711 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:50:32,002 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:51:32,236 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:52:32,536 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:53:32,700 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:54:33,054 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:55:33,364 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:56:35,793 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:57:37,218 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:58:37,502 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 12:59:37,674 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:00:37,966 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:01:38,235 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:02:38,486 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:03:38,654 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:04:38,827 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:05:39,145 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:06:39,327 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:07:39,562 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:08:39,703 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:09:39,900 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:10:40,103 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:11:40,288 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:12:40,532 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:13:40,789 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:14:41,072 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:15:41,718 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:16:42,361 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:17:42,817 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:18:43,102 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:19:43,359 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:20:43,542 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:21:43,723 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:22:44,039 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:23:44,286 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:24:44,469 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:25:44,675 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:26:44,883 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:27:45,140 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:28:45,360 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:29:45,615 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:30:45,794 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:31:45,976 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:32:46,233 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:33:46,463 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:34:46,677 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:35:46,874 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:36:47,079 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:37:47,508 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:38:47,678 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:39:47,880 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:40:48,120 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:41:48,599 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:42:49,874 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:43:50,176 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:44:50,411 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:45:50,646 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:46:50,920 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:47:51,308 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:48:51,506 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:49:51,697 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:50:51,899 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:51:52,128 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:52:52,448 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:53:52,652 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:54:52,852 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:55:53,112 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:56:53,313 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:57:53,738 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:58:53,954 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 13:59:54,189 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:00:54,383 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:01:54,626 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:02:55,494 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:03:55,870 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:04:56,111 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:05:56,367 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:06:56,595 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:07:56,937 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:08:57,118 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:09:57,352 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:10:57,508 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:11:57,731 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:12:57,932 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:13:58,122 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:15:03,921 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:16:04,103 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:17:04,439 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:18:04,694 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:19:05,037 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:20:05,268 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:21:05,491 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:22:05,885 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:23:06,146 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:24:06,864 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:25:07,341 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:26:07,538 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:27:07,941 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:28:08,392 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:29:08,832 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:30:09,092 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:31:09,367 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:32:09,775 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:33:10,948 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:34:11,613 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:35:12,002 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:36:14,344 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:37:15,584 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:38:22,483 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:39:23,022 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:40:23,496 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:41:24,002 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:42:24,442 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:43:24,743 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:44:24,959 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:45:25,467 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:46:25,866 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:47:26,392 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:48:26,744 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:49:26,976 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:50:27,215 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:51:27,467 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:52:27,867 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:53:28,208 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:54:28,625 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:55:28,855 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:56:29,095 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:57:29,310 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:58:29,730 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 14:59:29,964 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:00:30,185 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:01:30,417 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:02:30,663 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:03:31,058 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:04:31,306 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:05:31,718 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:06:31,924 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:07:32,192 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:08:32,393 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:09:32,619 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:10:32,896 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:11:33,094 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:12:33,355 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:13:33,718 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:14:34,015 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:15:34,351 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:16:34,622 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:17:34,895 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:18:35,187 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:19:35,465 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:20:35,729 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:21:36,173 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:22:36,441 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:23:36,728 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:24:37,177 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:25:37,737 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:26:37,998 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:27:38,322 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:28:38,668 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:29:38,959 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:30:39,325 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:31:43,866 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:32:44,935 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:33:46,342 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:34:46,732 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:35:47,895 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:36:48,700 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:37:49,194 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:38:49,821 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:39:50,396 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:40:52,896 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:42:02,775 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:43:07,124 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:44:10,768 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:45:11,895 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:46:13,107 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:47:13,673 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:48:14,295 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:49:22,452 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:50:24,080 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:51:24,557 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:52:24,799 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:53:25,607 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:54:26,467 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:55:27,074 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:56:27,419 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:57:27,940 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:58:28,541 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 15:59:28,884 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:00:29,095 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:01:29,586 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:02:29,851 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:03:30,271 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:04:30,583 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:05:30,788 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:06:31,073 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:07:31,420 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:08:31,644 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:09:32,056 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:10:32,363 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:11:32,786 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:12:33,214 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:13:33,917 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:14:34,401 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:15:35,323 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:16:35,860 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:17:36,753 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:18:37,186 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:19:37,703 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:20:38,126 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:21:38,576 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:22:41,952 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:23:42,246 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:24:42,683 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:25:43,108 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:26:43,829 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:27:44,506 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:28:44,818 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:29:45,053 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:30:45,581 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:31:46,124 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:32:46,562 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:33:47,664 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:34:48,965 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:35:49,393 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:36:50,318 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:37:50,592 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:38:50,946 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:39:51,200 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:40:51,417 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:41:51,647 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:42:51,982 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:43:52,251 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:44:52,489 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:45:52,773 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:46:53,031 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:47:53,226 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:48:53,451 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:49:53,821 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:50:54,067 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:51:54,297 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:52:54,577 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:53:54,796 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:54:55,065 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:55:55,453 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:56:55,887 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:57:56,140 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:58:56,358 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 16:59:56,598 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:00:56,883 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:01:57,105 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:02:57,368 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:03:57,619 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:04:57,914 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:05:58,182 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:06:58,406 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:07:58,611 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:08:58,850 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:09:59,136 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:10:59,357 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:11:59,638 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:12:59,911 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:14:00,134 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:15:00,372 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:16:00,606 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:17:00,856 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:18:01,045 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:19:01,307 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:20:01,594 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:21:01,884 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:22:02,070 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:23:02,348 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:24:02,587 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:25:02,830 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:26:03,035 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:27:03,307 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:28:03,498 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:29:03,718 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:30:03,970 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:31:04,183 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:32:04,443 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:33:04,650 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:34:04,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:35:05,484 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:36:05,704 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:37:05,968 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:38:06,233 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:39:06,508 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:40:06,747 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:41:06,960 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:42:07,175 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:43:07,447 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:44:07,670 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:45:07,928 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:46:08,117 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:47:08,312 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:48:08,533 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:49:08,716 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:50:09,060 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:51:09,301 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:52:09,528 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:53:09,693 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:54:09,907 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:55:10,108 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:56:10,347 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:57:10,543 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:58:10,795 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 17:59:10,968 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:00:11,252 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:01:11,473 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:02:11,707 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:03:11,906 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:04:12,139 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:05:12,320 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:06:12,601 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:07:12,811 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:08:13,026 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:09:13,240 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:10:13,459 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:11:13,611 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:12:13,791 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:13:13,976 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:14:14,161 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:15:14,395 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:16:14,696 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:17:14,916 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:18:15,091 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:19:15,328 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:20:15,572 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:21:15,762 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:22:16,147 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:23:16,340 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:24:16,522 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:25:16,798 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:26:16,992 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:27:17,242 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:28:17,542 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:29:17,822 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:30:18,059 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:31:18,343 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:32:18,587 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:33:18,827 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:34:19,084 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:35:19,364 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:36:19,786 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:37:20,090 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:38:20,422 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:39:20,953 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:40:21,237 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:41:21,669 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:42:21,935 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:43:22,253 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:44:22,466 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:45:22,695 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:46:22,919 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:47:23,134 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:48:23,316 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:49:23,574 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:50:23,805 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:51:24,070 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:52:24,296 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:53:24,532 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:54:24,692 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:55:24,979 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:56:25,241 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:57:25,451 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:58:25,625 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 18:59:25,865 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:00:26,110 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:01:26,305 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:02:26,535 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:03:26,825 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:04:27,037 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:05:27,275 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:06:27,495 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:07:27,721 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:08:27,939 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:09:28,188 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:10:28,415 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:11:28,657 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:12:28,853 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:13:29,150 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:14:29,341 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:15:29,578 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:16:29,825 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:17:30,065 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:18:30,312 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:19:30,518 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:20:30,709 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:21:30,913 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:22:31,124 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:23:31,333 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:24:31,596 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:25:31,805 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:26:32,014 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:27:32,170 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:28:32,388 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:29:32,634 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:30:32,869 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:31:33,024 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:32:33,234 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:33:33,472 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:34:33,659 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:35:33,906 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:36:34,127 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:37:34,298 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:38:34,504 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:39:34,709 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:40:34,980 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:41:35,209 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:42:35,408 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:43:35,712 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:44:35,921 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:45:36,178 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:46:36,441 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:47:36,613 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:48:36,821 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:49:37,020 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:50:37,272 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:51:37,498 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:52:37,688 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:53:37,940 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:54:38,106 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:55:38,298 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:56:38,455 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:57:38,651 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:58:39,064 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 19:59:39,216 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:00:39,389 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:01:39,605 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:02:39,767 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:03:39,958 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:04:40,181 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:05:40,365 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:06:40,508 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:07:40,685 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:08:40,916 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:09:41,163 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:10:41,410 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:11:41,598 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:12:41,757 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:13:41,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:14:42,095 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:15:42,308 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:16:42,466 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:17:42,692 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:18:42,925 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:19:43,129 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:20:43,306 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:21:43,482 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:22:43,649 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:23:43,850 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:24:44,003 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:25:44,200 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:26:44,369 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:27:44,558 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:28:44,737 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:29:44,906 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:30:45,174 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:31:45,355 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:32:45,510 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:33:45,740 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:34:46,040 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:35:46,223 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:36:46,425 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:37:46,625 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:38:46,916 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:39:47,124 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:40:47,357 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:41:47,549 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:42:47,834 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:43:48,075 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:44:48,321 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:45:48,515 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:46:48,714 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:47:49,028 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:48:49,253 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:49:49,499 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:50:49,712 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:51:49,952 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:52:50,153 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:53:50,375 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:54:50,607 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:55:50,803 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:56:51,008 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:57:51,166 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:58:51,331 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 20:59:51,522 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:00:51,724 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:01:51,947 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:02:52,118 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:03:52,371 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:04:52,613 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:05:52,867 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:06:53,085 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:07:53,294 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:08:53,598 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:09:53,830 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:10:54,031 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:11:54,253 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:12:54,529 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:13:54,721 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:14:54,950 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:15:55,156 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:16:55,351 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:17:55,546 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:18:55,773 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:19:55,986 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:20:56,288 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:21:56,633 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:22:56,851 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:23:57,055 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:24:57,306 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:25:57,513 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:26:57,748 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:27:57,923 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:28:58,154 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:29:58,335 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:30:58,595 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:31:58,799 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:32:58,962 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:33:59,179 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:34:59,386 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:35:59,575 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:36:59,754 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:37:59,939 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:39:00,136 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:40:00,362 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:41:00,591 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:42:00,769 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:43:00,976 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:44:01,173 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:45:01,377 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:46:01,551 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:47:01,726 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:48:01,958 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:49:02,166 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:50:02,388 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:51:02,627 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:52:02,883 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:53:03,104 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:54:03,282 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:55:03,447 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:56:03,638 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:57:03,841 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:58:04,007 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 21:59:04,255 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:00:04,469 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:01:04,676 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:02:04,844 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:03:04,988 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:04:05,195 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:05:05,379 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:06:05,583 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:07:05,776 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:08:05,989 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:09:06,190 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:10:06,381 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:11:06,548 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:12:06,697 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:13:06,894 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:14:07,100 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:15:07,291 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:16:07,541 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:17:07,756 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:18:07,935 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:19:08,107 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:20:08,271 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:21:08,507 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:22:08,731 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:23:08,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:24:09,093 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:25:09,293 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:26:09,508 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:27:09,676 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:28:09,831 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:29:09,997 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:30:10,178 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:31:10,352 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:32:10,525 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:33:10,729 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:34:10,910 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:35:11,133 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:36:11,334 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:37:11,512 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:38:11,734 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:39:11,910 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:40:12,088 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:41:12,267 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:42:12,423 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:43:12,607 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:44:12,797 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:45:13,002 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:46:13,193 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:47:13,377 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:48:13,536 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:49:13,726 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:50:13,890 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:51:14,080 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:52:14,372 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:53:14,644 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:54:14,834 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:55:15,044 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:56:15,350 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:57:15,527 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:58:15,785 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 22:59:16,006 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:00:16,193 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:01:16,380 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:02:16,586 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:03:16,751 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:04:16,967 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:05:17,187 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:06:17,384 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:07:17,612 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:08:17,861 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:09:18,097 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:10:18,272 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:11:18,465 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:12:18,654 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:13:18,859 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:14:19,089 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:15:19,292 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:16:19,463 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:17:19,648 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:18:19,928 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:19:20,129 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:20:20,311 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:21:20,563 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:22:20,786 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:23:20,997 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:24:21,213 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:25:21,432 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:26:21,607 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:27:21,808 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:28:22,022 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:29:22,275 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:30:22,448 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:31:22,647 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:32:22,856 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:33:23,045 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:34:23,248 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:35:23,470 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:36:23,672 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:37:23,826 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:38:24,027 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:39:24,220 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:40:24,442 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:41:24,644 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:42:24,881 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:43:25,077 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:44:25,301 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:45:25,482 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:46:25,674 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:47:25,920 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:48:26,113 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:49:26,270 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:50:26,451 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:51:26,633 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:52:26,824 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:53:26,973 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:54:27,229 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:55:27,479 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:56:27,665 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:57:27,830 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:58:28,040 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-09 23:59:28,263 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:00:28,609 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:01:28,828 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:02:28,977 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:03:29,158 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:04:29,404 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:05:29,597 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:06:30,072 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:07:30,273 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:08:30,482 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:09:30,653 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:10:30,829 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:11:31,057 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:12:31,258 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:13:31,453 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:14:31,704 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:15:31,894 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:16:32,082 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:17:32,273 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:18:32,532 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:19:32,702 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:20:32,877 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:21:33,088 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:22:33,274 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 00:23:33,461 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1193881298 cTime = 1568657882761 ; clusterId = CID-17626bae-6437-41c4-86cc-0b77d175031b ; blockpoolId = BP-654726240-127.0.1.1-1568657882761.
Expecting respectively: -63; 614487484; 1568235506165; CID-51d3ad8d-f2a6-4911-b240-848f0634fc7a; BP-697312766-127.0.1.1-1568235506165.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 08:57:22,168 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 08:57:22,235 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 08:57:22,626 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 08:57:22,759 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 08:57:22,829 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 08:57:22,829 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 08:57:24,550 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 08:57:24,551 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 08:57:24,593 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 08:57:24,750 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 4368@H6
2019-10-10 08:57:24,794 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 08:57:24,795 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 08:57:24,797 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 08:57:24,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 08:57:24,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 08:57:24,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 08:57:24,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 08:57:24
2019-10-10 08:57:24,839 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 08:57:24,839 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 08:57:24,840 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 08:57:24,840 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 08:57:24,861 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 08:57:24,863 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-10 08:57:24,863 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 08:57:24,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 08:57:24,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 08:57:24,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 08:57:24,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 08:57:24,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 08:57:24,865 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 08:57:24,865 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 08:57:24,865 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 08:57:24,865 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 08:57:24,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 08:57:24,925 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 08:57:24,925 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 08:57:24,925 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 08:57:24,925 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 08:57:24,946 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 08:57:24,946 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 08:57:24,946 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 08:57:24,953 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 08:57:24,953 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 08:57:24,953 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 08:57:24,953 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 08:57:24,955 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 08:57:24,955 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 08:57:24,955 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 08:57:24,958 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 08:57:24,958 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 08:57:24,958 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 08:57:25,064 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 08:57:25,065 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 08:57:25,072 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 08:57:25,118 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 08:57:25,126 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 08:57:25,130 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 08:57:25,137 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 08:57:25,140 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 08:57:25,140 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 08:57:25,140 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 08:57:25,157 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 08:57:25,158 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 08:57:25,314 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 08:57:25,314 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 09:35:08,698 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 09:37:15,480 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 09:37:15,488 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 09:37:15,860 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 09:37:15,965 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 09:37:16,019 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 09:37:16,019 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 09:37:16,623 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 09:37:16,623 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 09:37:16,855 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 09:37:17,290 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 11390@H6
2019-10-10 09:37:17,374 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 09:37:17,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 09:37:17,377 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 09:37:17,405 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 09:37:17,405 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 09:37:17,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 09:37:17,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 09:37:17
2019-10-10 09:37:17,408 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 09:37:17,408 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 09:37:17,409 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 09:37:17,410 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 09:37:17,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 09:37:17,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-10 09:37:17,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 09:37:17,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 09:37:17,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 09:37:17,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 09:37:17,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 09:37:17,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 09:37:17,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 09:37:17,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 09:37:17,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 09:37:17,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 09:37:17,428 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 09:37:17,479 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 09:37:17,479 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 09:37:17,480 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 09:37:17,480 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 09:37:17,482 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 09:37:17,482 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 09:37:17,482 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 09:37:17,488 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 09:37:17,488 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 09:37:17,488 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 09:37:17,488 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 09:37:17,490 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 09:37:17,490 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 09:37:17,490 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 09:37:17,493 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 09:37:17,493 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 09:37:17,493 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 09:37:17,516 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 09:37:17,516 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 09:37:17,522 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 09:37:17,567 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 09:37:17,574 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 09:37:17,578 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 09:37:17,583 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 09:37:17,585 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 09:37:17,585 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 09:37:17,585 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 09:37:17,597 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 09:37:17,597 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 09:37:17,982 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 09:37:17,982 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 09:41:12,737 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 09:41:12,746 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 09:51:24,161 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 09:51:24,213 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 09:51:24,548 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 09:51:24,650 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 09:51:24,706 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 09:51:24,706 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 09:51:24,829 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 09:51:24,829 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 09:51:24,867 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 09:51:24,930 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 4923@H6
2019-10-10 09:51:24,960 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 09:51:24,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 09:51:24,962 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 09:51:24,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 09:51:24,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 09:51:24,992 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 09:51:24,992 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 09:51:24
2019-10-10 09:51:24,994 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 09:51:24,994 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 09:51:24,995 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 09:51:24,995 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 09:51:25,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 09:51:25,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-10 09:51:25,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 09:51:25,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 09:51:25,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 09:51:25,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 09:51:25,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 09:51:25,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 09:51:25,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 09:51:25,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 09:51:25,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 09:51:25,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 09:51:25,013 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 09:51:25,063 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 09:51:25,063 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 09:51:25,063 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 09:51:25,063 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 09:51:25,065 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 09:51:25,065 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 09:51:25,065 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 09:51:25,071 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 09:51:25,071 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 09:51:25,071 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 09:51:25,071 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 09:51:25,073 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 09:51:25,073 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 09:51:25,073 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 09:51:25,075 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 09:51:25,075 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 09:51:25,075 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 09:51:25,112 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 09:51:25,112 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 09:51:25,118 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 09:51:25,168 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 09:51:25,174 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 09:51:25,178 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 09:51:25,183 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 09:51:25,185 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 09:51:25,185 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 09:51:25,185 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 09:51:25,197 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 09:51:25,197 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 09:51:25,316 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 09:51:25,316 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 09:53:01,049 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 09:53:01,051 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 10:13:55,213 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 10:13:55,221 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 10:13:55,550 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 10:13:55,660 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 10:13:55,716 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 10:13:55,716 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 10:13:55,820 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 10:13:55,820 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 10:13:55,859 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 10:13:55,915 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 7237@H6
2019-10-10 10:13:55,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 10:13:55,927 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 10:13:55,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 10:13:55,958 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 10:13:55,958 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 10:13:55,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 10:13:55,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 10:13:55
2019-10-10 10:13:55,961 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 10:13:55,961 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 10:13:55,962 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 10:13:55,962 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 10:13:55,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 10:13:55,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-10 10:13:55,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 10:13:55,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 10:13:55,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 10:13:55,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 10:13:55,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 10:13:55,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 10:13:55,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 10:13:55,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 10:13:55,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 10:13:55,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 10:13:55,980 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 10:13:56,033 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 10:13:56,033 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 10:13:56,033 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 10:13:56,033 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 10:13:56,035 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 10:13:56,035 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 10:13:56,035 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 10:13:56,042 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 10:13:56,042 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 10:13:56,042 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 10:13:56,042 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 10:13:56,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 10:13:56,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 10:13:56,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 10:13:56,047 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 10:13:56,047 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 10:13:56,047 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 10:13:56,056 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 10:13:56,056 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 10:13:56,083 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 10:13:56,129 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 10:13:56,136 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 10:13:56,141 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 10:13:56,145 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 10:13:56,149 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 10:13:56,149 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 10:13:56,149 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 10:13:56,161 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 10:13:56,161 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 10:13:56,275 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 10:13:56,277 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 10:41:57,899 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-10 10:41:58,357 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906&bootstrapstandby=false
2019-10-10 10:41:58,417 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-10 10:41:58,712 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 0.00 KB/s
2019-10-10 10:41:58,712 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 322 bytes.
2019-10-10 10:41:58,804 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=27&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 10:41:58,854 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 42.55 KB/s
2019-10-10 10:41:58,854 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000027_0000000000003604526 size 0 bytes.
2019-10-10 10:41:58,982 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-10-10 10:41:59,117 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-10 10:41:59,117 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000000
2019-10-10 10:41:59,117 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-10 10:41:59,125 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-10 10:41:59,145 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000001-0000000000000000027 expecting start txid #1
2019-10-10 10:41:59,145 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000001-0000000000000000027
2019-10-10 10:41:59,352 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 2 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570716854321_0001/job.jar
2019-10-10 10:41:59,423 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000001-0000000000000000027 of size 2366 edits # 27 loaded in 0 seconds
2019-10-10 10:41:59,452 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000027 using no compression
2019-10-10 10:41:59,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000027 of size 861 bytes saved in 0 seconds.
2019-10-10 10:41:59,580 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /home/luroz/hadoop/store/checkpoint
2019-10-10 10:41:59,587 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /home/luroz/hadoop/store/checkpoint
2019-10-10 10:41:59,845 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 27 to namenode at http://localhost:50070 in 0.183 seconds
2019-10-10 10:41:59,845 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 861
2019-10-10 11:42:01,168 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-10 11:42:01,218 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=28&endTxId=308&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 11:42:01,277 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 446.43 KB/s
2019-10-10 11:42:01,277 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000028-0000000000000000308_0000000000007206940 size 0 bytes.
2019-10-10 11:42:01,277 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-10 11:42:01,277 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000028-0000000000000000308 expecting start txid #28
2019-10-10 11:42:01,278 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000028-0000000000000000308
2019-10-10 11:42:01,299 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 2 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570716854321_0002/job.jar
2019-10-10 11:42:01,299 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 2 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570716854321_0002/job.split
2019-10-10 11:42:01,301 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 2 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570716854321_0003/job.jar
2019-10-10 11:42:01,301 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 2 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570716854321_0003/job.split
2019-10-10 11:42:01,303 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000028-0000000000000000308 of size 26381 edits # 281 loaded in 0 seconds
2019-10-10 11:42:01,303 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000308 using no compression
2019-10-10 11:42:01,308 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000308 of size 4205 bytes saved in 0 seconds.
2019-10-10 11:42:01,410 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 27
2019-10-10 11:42:01,410 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-10-10 11:42:01,627 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 308 to namenode at http://localhost:50070 in 0.141 seconds
2019-10-10 11:42:01,627 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4205
2019-10-10 11:50:52,477 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 11:50:52,484 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 11:51:37,067 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 11:51:37,074 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 11:51:37,409 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 11:51:37,519 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 11:51:37,571 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 11:51:37,571 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 11:51:37,739 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 11:51:37,740 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 11:51:37,779 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 11:51:37,826 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 16927@H6
2019-10-10 11:51:37,843 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 11:51:37,844 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 11:51:37,845 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 11:51:37,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 11:51:37,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 11:51:37,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 11:51:37,876 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 11:51:37
2019-10-10 11:51:37,877 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 11:51:37,877 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 11:51:37,879 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 11:51:37,879 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 11:51:37,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 11:51:37,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-10 11:51:37,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 11:51:37,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 11:51:37,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 11:51:37,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 11:51:37,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 11:51:37,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 11:51:37,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 11:51:37,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 11:51:37,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 11:51:37,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 11:51:37,897 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 11:51:37,946 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 11:51:37,946 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 11:51:37,946 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 11:51:37,946 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 11:51:37,948 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 11:51:37,948 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 11:51:37,948 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 11:51:37,954 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 11:51:37,954 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 11:51:37,954 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 11:51:37,954 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 11:51:37,956 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 11:51:37,956 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 11:51:37,956 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 11:51:37,959 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 11:51:37,959 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 11:51:37,959 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 11:51:37,991 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 11:51:37,992 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 11:51:37,999 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 11:51:38,043 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 11:51:38,049 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 11:51:38,053 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 11:51:38,058 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 11:51:38,060 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 11:51:38,060 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 11:51:38,060 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 11:51:38,072 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 11:51:38,072 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 11:51:38,184 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 11:51:38,184 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 11:52:38,579 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-10 11:52:39,141 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=308&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906&bootstrapstandby=false
2019-10-10 11:52:39,205 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-10 11:52:39,525 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 102.56 KB/s
2019-10-10 11:52:39,525 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000308 size 4205 bytes.
2019-10-10 11:52:39,576 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=309&endTxId=337&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 11:52:39,684 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.10s at 9846.15 KB/s
2019-10-10 11:52:39,684 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000309-0000000000000000337_0000000000007845297 size 0 bytes.
2019-10-10 11:52:39,685 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=338&endTxId=339&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 11:52:39,742 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2019-10-10 11:52:39,743 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000338-0000000000000000339_0000000000007845406 size 0 bytes.
2019-10-10 11:52:39,784 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 50 INodes.
2019-10-10 11:52:39,819 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-10 11:52:39,819 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 308 from /home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000308
2019-10-10 11:52:39,819 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-10 11:52:39,823 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-10-10 11:52:39,827 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000309-0000000000000000337 expecting start txid #309
2019-10-10 11:52:39,827 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000309-0000000000000000337
2019-10-10 11:52:39,861 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 2 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570716854321_0004/job.jar
2019-10-10 11:52:39,862 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 2 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570716854321_0004/job.split
2019-10-10 11:52:39,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000309-0000000000000000337 of size 1048576 edits # 29 loaded in 0 seconds
2019-10-10 11:52:39,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000338-0000000000000000339 expecting start txid #338
2019-10-10 11:52:39,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000338-0000000000000000339
2019-10-10 11:52:39,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000338-0000000000000000339 of size 42 edits # 2 loaded in 0 seconds
2019-10-10 11:52:39,870 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000339 using no compression
2019-10-10 11:52:39,902 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000339 of size 4567 bytes saved in 0 seconds.
2019-10-10 11:52:39,996 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 308
2019-10-10 11:52:39,996 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000027, cpktTxId=0000000000000000027)
2019-10-10 11:52:40,350 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 339 to namenode at http://localhost:50070 in 0.257 seconds
2019-10-10 11:52:40,351 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4567
2019-10-10 12:52:41,005 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-10 12:52:41,016 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=340&endTxId=369&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 12:52:41,069 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 40.00 KB/s
2019-10-10 12:52:41,069 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000340-0000000000000000369_0000000000011446737 size 0 bytes.
2019-10-10 12:52:41,069 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-10 12:52:41,069 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000340-0000000000000000369 expecting start txid #340
2019-10-10 12:52:41,069 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000340-0000000000000000369
2019-10-10 12:52:41,071 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 2 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570722715114_0001/job.jar
2019-10-10 12:52:41,071 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 2 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570722715114_0001/job.split
2019-10-10 12:52:41,074 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000340-0000000000000000369 of size 3054 edits # 30 loaded in 0 seconds
2019-10-10 12:52:41,074 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000369 using no compression
2019-10-10 12:52:41,080 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000369 of size 4929 bytes saved in 0 seconds.
2019-10-10 12:52:41,153 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 339
2019-10-10 12:52:41,153 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000308, cpktTxId=0000000000000000308)
2019-10-10 12:52:41,316 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 369 to namenode at http://localhost:50070 in 0.138 seconds
2019-10-10 12:52:41,316 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4929
2019-10-10 13:14:42,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:14:43,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:14:44,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:14:45,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:14:46,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:14:47,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:14:48,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:14:49,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:14:50,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:14:51,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:14:51,597 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 13:14:51,619 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 21 more
2019-10-10 13:15:52,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:15:53,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:15:54,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:15:55,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:15:56,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:15:57,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:15:58,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:15:59,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:16:00,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:16:01,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:16:01,669 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 13:16:01,670 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 21 more
2019-10-10 13:17:02,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:17:03,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:17:04,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:17:05,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:17:06,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:17:07,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:17:08,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:17:09,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:17:10,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:17:11,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:17:11,681 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 13:17:11,682 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 21 more
2019-10-10 13:18:12,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:18:13,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:18:14,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:18:15,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:18:16,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:18:17,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:18:18,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:18:19,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:18:20,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:18:21,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:18:21,693 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 13:18:21,694 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 21 more
2019-10-10 13:18:52,582 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 13:18:52,583 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 13:35:15,818 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 13:35:15,872 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 13:35:16,214 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 13:35:16,320 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 13:35:16,376 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 13:35:16,376 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 13:35:19,252 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 13:35:19,253 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 13:35:19,293 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 13:35:19,602 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 3536@H6
2019-10-10 13:35:19,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 13:35:19,892 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 13:35:19,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 13:35:19,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 13:35:19,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 13:35:19,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 13:35:19,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 13:35:19
2019-10-10 13:35:19,944 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 13:35:19,944 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 13:35:19,945 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 13:35:19,945 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 13:35:19,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 13:35:19,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-10 13:35:19,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 13:35:19,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 13:35:19,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 13:35:19,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 13:35:19,962 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 13:35:19,962 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 13:35:19,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 13:35:19,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 13:35:19,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 13:35:19,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 13:35:19,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 13:35:20,061 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 13:35:20,061 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 13:35:20,062 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 13:35:20,062 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 13:35:20,062 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 13:35:20,062 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 13:35:20,062 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 13:35:20,069 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 13:35:20,069 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 13:35:20,069 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 13:35:20,069 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 13:35:20,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 13:35:20,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 13:35:20,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 13:35:20,112 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 13:35:20,112 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 13:35:20,113 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 13:35:20,251 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 13:35:20,251 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 13:35:20,258 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 13:35:20,324 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 13:35:20,337 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 13:35:20,342 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 13:35:20,346 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 13:35:20,348 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 13:35:20,348 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 13:35:20,348 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 13:35:20,360 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 13:35:20,360 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 13:35:20,565 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 13:35:20,566 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 13:53:22,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:53:23,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:53:24,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:53:25,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:53:26,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:53:27,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:53:28,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:53:29,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:53:30,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:53:31,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:53:31,030 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 13:53:31,039 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 21 more
2019-10-10 13:54:32,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:54:33,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:54:34,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:54:35,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:54:36,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:54:37,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:54:38,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:54:39,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:54:40,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:54:41,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:54:41,057 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 13:54:41,058 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 21 more
2019-10-10 13:55:42,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:55:43,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:55:44,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:55:45,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:55:46,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:55:47,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:55:48,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:55:49,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:55:50,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:55:51,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 13:55:51,070 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 13:55:51,071 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 21 more
2019-10-10 13:56:49,553 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 13:56:49,569 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 14:04:16,368 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 14:04:16,376 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 14:04:16,713 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 14:04:16,821 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 14:04:16,878 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 14:04:16,878 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 14:04:16,982 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 14:04:16,982 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 14:04:17,021 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 14:04:17,062 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 8874@H6
2019-10-10 14:04:17,080 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 14:04:17,081 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 14:04:17,082 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 14:04:17,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 14:04:17,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 14:04:17,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 14:04:17,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 14:04:17
2019-10-10 14:04:17,115 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 14:04:17,115 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 14:04:17,117 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 14:04:17,117 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 14:04:17,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 14:04:17,132 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-10 14:04:17,132 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 14:04:17,132 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 14:04:17,132 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 14:04:17,132 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 14:04:17,132 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 14:04:17,132 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 14:04:17,134 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 14:04:17,134 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 14:04:17,134 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 14:04:17,134 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 14:04:17,136 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 14:04:17,193 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 14:04:17,193 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 14:04:17,194 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 14:04:17,194 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 14:04:17,196 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 14:04:17,196 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 14:04:17,196 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 14:04:17,203 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 14:04:17,203 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 14:04:17,203 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 14:04:17,203 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 14:04:17,205 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 14:04:17,205 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 14:04:17,205 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 14:04:17,209 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 14:04:17,209 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 14:04:17,209 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 14:04:17,232 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 14:04:17,232 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 14:04:17,238 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 14:04:17,283 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 14:04:17,289 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 14:04:17,294 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 14:04:17,298 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 14:04:17,300 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 14:04:17,300 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 14:04:17,300 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 14:04:17,312 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 14:04:17,312 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 14:04:17,459 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 14:04:17,459 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 14:19:18,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:19:19,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:19:20,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:19:21,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:19:22,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:19:23,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:19:24,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:19:25,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:19:26,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:19:27,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:19:27,686 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 14:19:27,694 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 22 more
2019-10-10 14:20:28,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:20:29,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:20:30,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:20:31,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:20:32,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:20:33,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:20:34,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:20:35,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:20:36,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:20:37,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 14:20:37,719 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 14:20:37,721 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 22 more
2019-10-10 14:20:39,048 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 14:20:39,051 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 14:33:01,803 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 14:33:01,864 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 14:33:02,260 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 14:33:02,372 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 14:33:02,425 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 14:33:02,425 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 14:33:02,678 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 14:33:02,678 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 14:33:02,718 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 14:33:02,825 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 4270@H6
2019-10-10 14:33:02,865 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 14:33:02,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 14:33:02,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 14:33:02,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 14:33:02,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 14:33:02,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 14:33:02,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 14:33:02
2019-10-10 14:33:02,898 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 14:33:02,898 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 14:33:02,899 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 14:33:02,899 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 14:33:02,911 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 14:33:02,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-10 14:33:02,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 14:33:02,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 14:33:02,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 14:33:02,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 14:33:02,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 14:33:02,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 14:33:02,915 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 14:33:02,915 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 14:33:02,915 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 14:33:02,916 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 14:33:02,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 14:33:02,969 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 14:33:02,969 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 14:33:02,969 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 14:33:02,969 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 14:33:02,971 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 14:33:02,971 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 14:33:02,971 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 14:33:02,977 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 14:33:02,977 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 14:33:02,977 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 14:33:02,977 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 14:33:02,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 14:33:02,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 14:33:02,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 14:33:02,981 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 14:33:02,981 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 14:33:02,981 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 14:33:03,065 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 14:33:03,065 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 14:33:03,072 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 14:33:03,116 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 14:33:03,123 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 14:33:03,127 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 14:33:03,131 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 14:33:03,133 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 14:33:03,133 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 14:33:03,133 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 14:33:03,147 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 14:33:03,147 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 14:33:03,278 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 14:33:03,279 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 15:08:04,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:08:05,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:08:06,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:08:07,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:08:08,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:08:09,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:08:10,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:08:11,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:08:12,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:08:13,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:08:13,961 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 15:08:13,969 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 21 more
2019-10-10 15:09:14,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:09:15,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:09:16,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:09:17,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:09:18,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:09:19,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:09:20,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:09:21,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:09:22,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:09:23,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:09:23,989 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 15:09:23,991 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 21 more
2019-10-10 15:10:18,269 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 15:10:18,270 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 15:16:59,346 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 15:16:59,353 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 15:16:59,691 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 15:16:59,807 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 15:16:59,866 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 15:16:59,866 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 15:16:59,972 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 15:16:59,972 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 15:17:00,012 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 15:17:00,055 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 9163@H6
2019-10-10 15:17:00,085 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 15:17:00,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 15:17:00,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 15:17:00,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 15:17:00,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 15:17:00,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 15:17:00,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 15:17:00
2019-10-10 15:17:00,121 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 15:17:00,121 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:17:00,122 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 15:17:00,122 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 15:17:00,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 15:17:00,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-10-10 15:17:00,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 15:17:00,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 15:17:00,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 15:17:00,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 15:17:00,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 15:17:00,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 15:17:00,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 15:17:00,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 15:17:00,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 15:17:00,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 15:17:00,141 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 15:17:00,210 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 15:17:00,210 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:17:00,211 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 15:17:00,211 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 15:17:00,213 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 15:17:00,213 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 15:17:00,213 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 15:17:00,220 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 15:17:00,220 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:17:00,220 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 15:17:00,221 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 15:17:00,222 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 15:17:00,223 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 15:17:00,223 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 15:17:00,227 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 15:17:00,227 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 15:17:00,227 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 15:17:00,256 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 15:17:00,256 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 15:17:00,262 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 15:17:00,306 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 15:17:00,312 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 15:17:00,316 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 15:17:00,321 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 15:17:00,322 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 15:17:00,323 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 15:17:00,323 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 15:17:00,335 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 15:17:00,335 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 15:17:00,491 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 15:17:00,491 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 15:23:36,492 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 15:23:36,494 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 15:25:22,928 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 15:25:22,936 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 15:25:23,276 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 15:25:23,380 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 15:25:23,440 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 15:25:23,440 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 15:25:23,543 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 15:25:23,543 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 15:25:23,583 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 15:25:23,905 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 11788@H6
2019-10-10 15:25:23,922 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 15:25:23,923 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 15:25:23,924 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 15:25:23,954 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 15:25:23,954 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 15:25:23,955 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 15:25:23,955 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 15:25:23
2019-10-10 15:25:23,957 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 15:25:23,957 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:25:23,958 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 15:25:23,958 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 15:25:23,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 15:25:23,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-10-10 15:25:23,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 15:25:23,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 15:25:23,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 15:25:23,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 15:25:23,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 15:25:23,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 15:25:23,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 15:25:23,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 15:25:23,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 15:25:23,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 15:25:23,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 15:25:24,026 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 15:25:24,027 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:25:24,027 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 15:25:24,027 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 15:25:24,029 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 15:25:24,029 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 15:25:24,029 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 15:25:24,035 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 15:25:24,036 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:25:24,036 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 15:25:24,036 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 15:25:24,037 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 15:25:24,037 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 15:25:24,037 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 15:25:24,040 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 15:25:24,041 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 15:25:24,041 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 15:25:24,063 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 15:25:24,063 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 15:25:24,069 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 15:25:24,112 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 15:25:24,118 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 15:25:24,122 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 15:25:24,126 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 15:25:24,128 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 15:25:24,129 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 15:25:24,129 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 15:25:24,141 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 15:25:24,141 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 15:25:24,235 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 15:25:24,235 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 15:26:24,559 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-10 15:26:24,882 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=585&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906&bootstrapstandby=false
2019-10-10 15:26:24,945 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-10 15:26:25,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.11s at 9.43 KB/s
2019-10-10 15:26:25,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000585 size 1657 bytes.
2019-10-10 15:26:25,345 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=586&endTxId=614&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 15:26:25,436 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 12487.80 KB/s
2019-10-10 15:26:25,436 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000586-0000000000000000614_0000000000003689066 size 0 bytes.
2019-10-10 15:26:25,437 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=615&endTxId=644&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 15:26:25,486 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 41.67 KB/s
2019-10-10 15:26:25,486 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000615-0000000000000000644_0000000000003689158 size 0 bytes.
2019-10-10 15:26:25,537 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 19 INodes.
2019-10-10 15:26:25,572 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-10 15:26:25,572 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 585 from /home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000585
2019-10-10 15:26:25,572 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-10 15:26:25,577 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-10-10 15:26:25,580 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000586-0000000000000000614 expecting start txid #586
2019-10-10 15:26:25,580 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000586-0000000000000000614
2019-10-10 15:26:25,618 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570735035500_0001/job.jar
2019-10-10 15:26:25,619 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570735035500_0001/job.split
2019-10-10 15:26:25,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000586-0000000000000000614 of size 1048576 edits # 29 loaded in 0 seconds
2019-10-10 15:26:25,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000615-0000000000000000644 expecting start txid #615
2019-10-10 15:26:25,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000615-0000000000000000644
2019-10-10 15:26:25,623 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570735536804_0001/job.jar
2019-10-10 15:26:25,624 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570735536804_0001/job.split
2019-10-10 15:26:25,626 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000615-0000000000000000644 of size 3050 edits # 30 loaded in 0 seconds
2019-10-10 15:26:25,634 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000644 using no compression
2019-10-10 15:26:25,667 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000644 of size 2380 bytes saved in 0 seconds.
2019-10-10 15:26:25,790 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 585
2019-10-10 15:26:25,790 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000339, cpktTxId=0000000000000000339)
2019-10-10 15:26:25,790 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000369, cpktTxId=0000000000000000369)
2019-10-10 15:26:26,002 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 644 to namenode at http://localhost:50070 in 0.14 seconds
2019-10-10 15:26:26,002 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2380
2019-10-10 15:31:27,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:31:28,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:31:29,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:31:30,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:31:31,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:31:32,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:31:33,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:31:34,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:31:35,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:31:36,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:31:36,033 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 15:31:36,040 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 22 more
2019-10-10 15:32:37,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:32:38,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:32:39,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:32:40,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:32:41,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:32:42,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:32:43,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:32:44,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:32:45,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:32:46,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:32:46,058 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 15:32:46,058 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 22 more
2019-10-10 15:32:54,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 15:32:54,070 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 15:37:12,458 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 15:37:12,467 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 15:37:12,804 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 15:37:12,909 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 15:37:12,967 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 15:37:12,967 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 15:37:13,071 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 15:37:13,072 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 15:37:13,112 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 15:37:13,153 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 14218@H6
2019-10-10 15:37:13,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 15:37:13,174 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 15:37:13,176 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 15:37:13,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 15:37:13,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 15:37:13,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 15:37:13,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 15:37:13
2019-10-10 15:37:13,209 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 15:37:13,209 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:37:13,210 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 15:37:13,210 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 15:37:13,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 15:37:13,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-10-10 15:37:13,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 15:37:13,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 15:37:13,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 15:37:13,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 15:37:13,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 15:37:13,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 15:37:13,228 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 15:37:13,228 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 15:37:13,228 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 15:37:13,228 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 15:37:13,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 15:37:13,284 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 15:37:13,285 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:37:13,285 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 15:37:13,285 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 15:37:13,287 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 15:37:13,287 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 15:37:13,287 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 15:37:13,294 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 15:37:13,294 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:37:13,294 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 15:37:13,294 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 15:37:13,296 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 15:37:13,296 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 15:37:13,296 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 15:37:13,299 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 15:37:13,299 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 15:37:13,299 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 15:37:13,323 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 15:37:13,323 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 15:37:13,329 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 15:37:13,374 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 15:37:13,381 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 15:37:13,389 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 15:37:13,393 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 15:37:13,395 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 15:37:13,395 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 15:37:13,395 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 15:37:13,407 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 15:37:13,407 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 15:37:13,511 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 15:37:13,511 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 15:38:13,739 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-10 15:38:13,934 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=644&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906&bootstrapstandby=false
2019-10-10 15:38:13,968 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-10 15:38:14,236 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 40.82 KB/s
2019-10-10 15:38:14,236 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000644 size 2380 bytes.
2019-10-10 15:38:14,295 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=645&endTxId=645&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 15:38:14,369 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 14422.54 KB/s
2019-10-10 15:38:14,370 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000645-0000000000000000645_0000000000004398016 size 0 bytes.
2019-10-10 15:38:14,370 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=646&endTxId=647&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 15:38:14,428 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2019-10-10 15:38:14,428 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000646-0000000000000000647_0000000000004398091 size 0 bytes.
2019-10-10 15:38:14,470 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 29 INodes.
2019-10-10 15:38:14,504 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-10 15:38:14,505 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 644 from /home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000644
2019-10-10 15:38:14,505 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-10 15:38:14,509 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-10-10 15:38:14,513 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000645-0000000000000000645 expecting start txid #645
2019-10-10 15:38:14,514 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000645-0000000000000000645
2019-10-10 15:38:14,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000645-0000000000000000645 of size 1048576 edits # 1 loaded in 0 seconds
2019-10-10 15:38:14,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000646-0000000000000000647 expecting start txid #646
2019-10-10 15:38:14,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000646-0000000000000000647
2019-10-10 15:38:14,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000646-0000000000000000647 of size 42 edits # 2 loaded in 0 seconds
2019-10-10 15:38:14,533 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000647 using no compression
2019-10-10 15:38:14,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000647 of size 2380 bytes saved in 0 seconds.
2019-10-10 15:38:14,616 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 644
2019-10-10 15:38:14,617 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000585, cpktTxId=0000000000000000585)
2019-10-10 15:38:14,900 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 647 to namenode at http://localhost:50070 in 0.189 seconds
2019-10-10 15:38:14,900 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2380
2019-10-10 15:51:16,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:51:17,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:51:18,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:51:19,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:51:20,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:51:21,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:51:22,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:51:23,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:51:24,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:51:25,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:51:25,355 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 15:51:25,363 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 22 more
2019-10-10 15:52:26,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:52:27,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:52:28,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:52:29,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:52:30,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:52:31,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:52:32,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:52:33,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:52:34,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:52:35,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 15:52:35,399 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 15:52:35,400 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 22 more
2019-10-10 15:52:41,972 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 15:52:41,974 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 15:58:50,944 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 15:58:50,955 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 15:58:51,298 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 15:58:51,411 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 15:58:51,474 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 15:58:51,474 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 15:58:51,619 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 15:58:51,619 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 15:58:51,661 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 15:58:51,698 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 17844@H6
2019-10-10 15:58:51,727 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 15:58:51,728 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 15:58:51,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 15:58:51,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 15:58:51,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 15:58:51,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 15:58:51,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 15:58:51
2019-10-10 15:58:51,762 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 15:58:51,762 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:58:51,763 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 15:58:51,763 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 15:58:51,776 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 15:58:51,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-10-10 15:58:51,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 15:58:51,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 15:58:51,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 15:58:51,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 15:58:51,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 15:58:51,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 15:58:51,780 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 15:58:51,780 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 15:58:51,780 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 15:58:51,780 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 15:58:51,782 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 15:58:51,832 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 15:58:51,833 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:58:51,833 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 15:58:51,833 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 15:58:51,835 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 15:58:51,835 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 15:58:51,835 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 15:58:51,841 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 15:58:51,841 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 15:58:51,841 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 15:58:51,841 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 15:58:51,843 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 15:58:51,843 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 15:58:51,843 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 15:58:51,846 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 15:58:51,846 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 15:58:51,846 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 15:58:51,880 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 15:58:51,880 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 15:58:51,886 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 15:58:51,933 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 15:58:51,940 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 15:58:51,945 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 15:58:51,950 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 15:58:51,952 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 15:58:51,952 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 15:58:51,952 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 15:58:51,965 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 15:58:51,965 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 15:58:52,107 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 15:58:52,108 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 15:59:52,504 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-10 15:59:52,914 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=647&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906&bootstrapstandby=false
2019-10-10 15:59:52,978 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-10 15:59:53,200 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 66.67 KB/s
2019-10-10 15:59:53,200 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000647 size 2380 bytes.
2019-10-10 15:59:53,259 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=648&endTxId=676&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 15:59:53,325 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 16516.13 KB/s
2019-10-10 15:59:53,325 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000648-0000000000000000676_0000000000005696980 size 0 bytes.
2019-10-10 15:59:53,326 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=677&endTxId=678&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 15:59:53,392 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2019-10-10 15:59:53,392 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000677-0000000000000000678_0000000000005697047 size 0 bytes.
2019-10-10 15:59:53,439 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 29 INodes.
2019-10-10 15:59:53,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-10 15:59:53,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 647 from /home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000647
2019-10-10 15:59:53,477 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-10 15:59:53,482 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-10-10 15:59:53,485 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000648-0000000000000000676 expecting start txid #648
2019-10-10 15:59:53,486 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000648-0000000000000000676
2019-10-10 15:59:53,520 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570736249340_0001/job.jar
2019-10-10 15:59:53,521 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570736249340_0001/job.split
2019-10-10 15:59:53,524 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000648-0000000000000000676 of size 1048576 edits # 29 loaded in 0 seconds
2019-10-10 15:59:53,524 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000677-0000000000000000678 expecting start txid #677
2019-10-10 15:59:53,524 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000677-0000000000000000678
2019-10-10 15:59:53,524 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000677-0000000000000000678 of size 42 edits # 2 loaded in 0 seconds
2019-10-10 15:59:53,529 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000678 using no compression
2019-10-10 15:59:53,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000678 of size 2741 bytes saved in 0 seconds.
2019-10-10 15:59:53,605 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 647
2019-10-10 15:59:53,606 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000644, cpktTxId=0000000000000000644)
2019-10-10 15:59:53,892 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 678 to namenode at http://localhost:50070 in 0.216 seconds
2019-10-10 15:59:53,892 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2741
2019-10-10 16:00:54,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:00:55,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:00:56,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:00:57,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:00:58,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:00:59,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:01:00,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:01:01,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:01:02,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:01:03,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:01:03,904 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 16:01:03,912 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 22 more
2019-10-10 16:02:04,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:02:05,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:02:06,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:02:07,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:02:08,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:02:09,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:02:10,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:02:11,921 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:02:12,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:02:13,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:02:13,923 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 16:02:13,924 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 22 more
2019-10-10 16:03:14,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:03:15,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:03:16,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:03:17,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:03:18,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:03:19,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:03:20,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:03:21,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:03:22,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:03:23,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:03:23,936 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 16:03:23,937 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From H6/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	... 22 more
2019-10-10 16:04:07,955 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 16:04:07,957 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 16:14:18,701 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 16:14:18,712 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 16:14:19,080 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 16:14:19,194 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 16:14:19,255 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 16:14:19,255 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 16:14:19,372 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 16:14:19,372 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 16:14:19,416 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 16:14:19,455 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 20167@H6
2019-10-10 16:14:19,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 16:14:19,474 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 16:14:19,475 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 16:14:19,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 16:14:19,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 16:14:19,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 16:14:19,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 16:14:19
2019-10-10 16:14:19,509 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 16:14:19,509 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 16:14:19,510 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 16:14:19,510 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 16:14:19,523 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 16:14:19,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-10-10 16:14:19,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 16:14:19,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 16:14:19,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 16:14:19,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 16:14:19,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 16:14:19,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 16:14:19,527 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 16:14:19,527 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 16:14:19,527 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 16:14:19,527 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 16:14:19,529 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 16:14:19,596 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 16:14:19,596 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 16:14:19,597 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 16:14:19,597 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 16:14:19,599 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 16:14:19,599 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 16:14:19,599 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 16:14:19,605 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 16:14:19,605 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 16:14:19,605 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 16:14:19,606 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 16:14:19,607 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 16:14:19,607 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 16:14:19,607 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 16:14:19,610 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 16:14:19,611 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 16:14:19,611 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 16:14:19,636 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 16:14:19,636 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 16:14:19,642 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 16:14:19,687 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 16:14:19,693 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 16:14:19,698 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 16:14:19,703 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 16:14:19,706 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 16:14:19,706 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 16:14:19,707 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 16:14:19,722 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 16:14:19,722 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 16:14:19,831 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 16:14:19,831 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 16:15:20,384 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-10 16:15:21,379 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=678&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906&bootstrapstandby=false
2019-10-10 16:15:21,538 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-10 16:15:21,792 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 43.48 KB/s
2019-10-10 16:15:21,792 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000678 size 2741 bytes.
2019-10-10 16:15:21,835 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=679&endTxId=679&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 16:15:21,909 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 14628.57 KB/s
2019-10-10 16:15:21,910 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000679-0000000000000000679_0000000000006625556 size 0 bytes.
2019-10-10 16:15:21,911 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=680&endTxId=681&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 16:15:21,976 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2019-10-10 16:15:21,977 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000680-0000000000000000681_0000000000006625631 size 0 bytes.
2019-10-10 16:15:22,019 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 34 INodes.
2019-10-10 16:15:22,055 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-10 16:15:22,055 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 678 from /home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000678
2019-10-10 16:15:22,055 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-10 16:15:22,060 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-10-10 16:15:22,063 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000679-0000000000000000679 expecting start txid #679
2019-10-10 16:15:22,064 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000679-0000000000000000679
2019-10-10 16:15:22,078 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000679-0000000000000000679 of size 1048576 edits # 1 loaded in 0 seconds
2019-10-10 16:15:22,078 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000680-0000000000000000681 expecting start txid #680
2019-10-10 16:15:22,078 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000680-0000000000000000681
2019-10-10 16:15:22,078 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000680-0000000000000000681 of size 42 edits # 2 loaded in 0 seconds
2019-10-10 16:15:22,082 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000681 using no compression
2019-10-10 16:15:22,115 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000681 of size 2741 bytes saved in 0 seconds.
2019-10-10 16:15:22,179 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 678
2019-10-10 16:15:22,180 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000647, cpktTxId=0000000000000000647)
2019-10-10 16:15:22,452 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 681 to namenode at http://localhost:50070 in 0.142 seconds
2019-10-10 16:15:22,453 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2741
2019-10-10 16:47:23,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:47:24,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-10-10 16:47:25,714 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 16:47:25,716 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-10 17:01:16,845 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-10 17:01:16,853 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-10 17:01:17,178 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-10 17:01:17,284 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-10 17:01:17,339 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-10 17:01:17,339 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-10 17:01:17,442 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 17:01:17,442 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-10 17:01:17,480 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-10 17:01:17,522 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 24798@H6
2019-10-10 17:01:17,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-10 17:01:17,533 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-10 17:01:17,535 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-10 17:01:17,565 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-10 17:01:17,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-10 17:01:17,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-10 17:01:17,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 10 17:01:17
2019-10-10 17:01:17,569 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-10 17:01:17,569 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 17:01:17,570 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-10 17:01:17,570 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-10 17:01:17,582 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-10 17:01:17,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-10-10 17:01:17,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-10 17:01:17,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-10 17:01:17,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-10 17:01:17,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-10 17:01:17,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-10 17:01:17,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-10 17:01:17,587 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-10 17:01:17,587 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-10 17:01:17,587 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-10 17:01:17,587 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-10 17:01:17,589 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-10 17:01:17,639 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-10 17:01:17,639 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 17:01:17,639 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-10 17:01:17,639 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-10 17:01:17,641 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-10 17:01:17,641 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-10 17:01:17,642 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-10 17:01:17,648 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-10 17:01:17,648 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-10 17:01:17,648 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-10 17:01:17,648 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-10 17:01:17,650 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-10 17:01:17,650 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-10 17:01:17,650 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-10 17:01:17,653 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-10 17:01:17,653 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-10 17:01:17,653 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-10 17:01:17,674 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-10 17:01:17,674 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-10 17:01:17,695 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-10 17:01:17,739 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-10 17:01:17,746 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-10 17:01:17,750 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-10 17:01:17,755 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-10 17:01:17,756 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-10 17:01:17,757 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-10 17:01:17,757 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-10 17:01:17,768 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-10 17:01:17,769 INFO org.mortbay.log: jetty-6.1.26
2019-10-10 17:01:17,899 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-10 17:01:17,900 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-10 17:02:17,991 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 30.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 17:03:18,002 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 30.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 17:04:18,012 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 30.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 17:05:18,022 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 30.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 17:06:18,031 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 30.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 17:07:18,058 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 30.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 17:08:18,066 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 30.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 17:09:18,077 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 30.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-10 17:10:18,312 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-10 17:10:18,700 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=681&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906&bootstrapstandby=false
2019-10-10 17:10:18,748 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-10 17:10:18,928 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 74.07 KB/s
2019-10-10 17:10:18,928 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000681 size 2741 bytes.
2019-10-10 17:10:18,987 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=682&endTxId=746&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 17:10:19,061 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 14422.54 KB/s
2019-10-10 17:10:19,062 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000682-0000000000000000746_0000000000009922708 size 0 bytes.
2019-10-10 17:10:19,063 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=747&endTxId=776&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 17:10:19,128 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 32.79 KB/s
2019-10-10 17:10:19,129 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000747-0000000000000000776_0000000000009922783 size 0 bytes.
2019-10-10 17:10:19,175 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 34 INodes.
2019-10-10 17:10:19,207 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-10 17:10:19,208 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 681 from /home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000681
2019-10-10 17:10:19,208 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-10 17:10:19,212 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-10-10 17:10:19,215 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000682-0000000000000000746 expecting start txid #682
2019-10-10 17:10:19,215 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000682-0000000000000000746
2019-10-10 17:10:19,250 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570738477400_0001/job.jar
2019-10-10 17:10:19,251 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570738477400_0001/job.split
2019-10-10 17:10:19,255 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570738477400_0002/job.jar
2019-10-10 17:10:19,256 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570738477400_0002/job.split
2019-10-10 17:10:19,266 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000682-0000000000000000746 of size 1048576 edits # 65 loaded in 0 seconds
2019-10-10 17:10:19,266 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000747-0000000000000000776 expecting start txid #747
2019-10-10 17:10:19,266 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000747-0000000000000000776
2019-10-10 17:10:19,267 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570741509901_0002/job.jar
2019-10-10 17:10:19,268 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570741509901_0002/job.split
2019-10-10 17:10:19,269 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000747-0000000000000000776 of size 3050 edits # 30 loaded in 0 seconds
2019-10-10 17:10:19,273 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000776 using no compression
2019-10-10 17:10:19,302 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000776 of size 3824 bytes saved in 0 seconds.
2019-10-10 17:10:19,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /home/luroz/hadoop/store/checkpoint
2019-10-10 17:10:19,372 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /home/luroz/hadoop/store/checkpoint
2019-10-10 17:10:19,648 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 776 to namenode at http://localhost:50070 in 0.228 seconds
2019-10-10 17:10:19,648 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 3824
2019-10-10 18:10:20,241 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-10 18:10:20,242 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=777&endTxId=806&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-10 18:10:20,296 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 39.22 KB/s
2019-10-10 18:10:20,296 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000777-0000000000000000806_0000000000013523963 size 0 bytes.
2019-10-10 18:10:20,296 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-10 18:10:20,296 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000777-0000000000000000806 expecting start txid #777
2019-10-10 18:10:20,296 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000777-0000000000000000806
2019-10-10 18:10:20,298 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570741509901_0003/job.jar
2019-10-10 18:10:20,298 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570741509901_0003/job.split
2019-10-10 18:10:20,299 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000777-0000000000000000806 of size 3058 edits # 30 loaded in 0 seconds
2019-10-10 18:10:20,300 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000806 using no compression
2019-10-10 18:10:20,305 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000806 of size 4185 bytes saved in 0 seconds.
2019-10-10 18:10:20,347 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 776
2019-10-10 18:10:20,347 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000681, cpktTxId=0000000000000000681)
2019-10-10 18:10:20,501 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 806 to namenode at http://localhost:50070 in 0.106 seconds
2019-10-10 18:10:20,501 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4185
2019-10-10 18:42:51,405 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-10 18:42:51,422 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-11 09:46:42,407 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-11 09:46:42,458 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-11 09:46:42,841 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-11 09:46:42,947 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-11 09:46:43,003 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-11 09:46:43,003 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-11 09:46:43,199 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-11 09:46:43,199 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/luroz/hadoop/store/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-11 09:46:43,238 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-11 09:46:43,351 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/luroz/hadoop/store/checkpoint/in_use.lock acquired by nodename 8940@H6
2019-10-11 09:46:43,396 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-11 09:46:43,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-11 09:46:43,399 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-11 09:46:43,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-11 09:46:43,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-11 09:46:43,430 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-11 09:46:43,430 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 11 09:46:43
2019-10-11 09:46:43,432 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-11 09:46:43,432 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-11 09:46:43,433 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-11 09:46:43,433 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-11 09:46:43,446 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-11 09:46:43,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-10-11 09:46:43,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-11 09:46:43,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-11 09:46:43,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-11 09:46:43,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-11 09:46:43,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-11 09:46:43,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-11 09:46:43,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-11 09:46:43,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-11 09:46:43,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-11 09:46:43,451 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-11 09:46:43,452 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-11 09:46:43,503 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-11 09:46:43,503 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-11 09:46:43,503 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-11 09:46:43,503 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-11 09:46:43,505 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-11 09:46:43,505 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-11 09:46:43,505 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-11 09:46:43,511 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-11 09:46:43,512 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-11 09:46:43,512 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-11 09:46:43,512 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-11 09:46:43,513 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-11 09:46:43,513 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-11 09:46:43,513 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-11 09:46:43,516 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-11 09:46:43,517 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-11 09:46:43,517 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-11 09:46:43,541 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-11 09:46:43,541 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-11 09:46:43,547 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-11 09:46:43,592 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-11 09:46:43,598 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-11 09:46:43,603 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-11 09:46:43,607 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-11 09:46:43,609 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-11 09:46:43,609 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-11 09:46:43,609 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-11 09:46:43,622 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-11 09:46:43,622 INFO org.mortbay.log: jetty-6.1.26
2019-10-11 09:46:43,782 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-11 09:46:43,782 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-11 10:02:44,464 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:03:44,475 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:04:44,486 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:05:44,497 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:06:44,508 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:07:44,527 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:08:44,536 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:09:44,546 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:10:44,555 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:11:44,566 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:12:43,301 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:13:43,309 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:14:43,318 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:15:43,336 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:16:43,345 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:17:43,363 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:18:43,372 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:19:43,868 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:20:42,814 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:21:42,822 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:22:45,044 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:23:46,006 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:24:46,015 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:25:44,861 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:26:44,418 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:27:44,404 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:28:44,412 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:29:44,420 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:30:44,428 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:31:44,845 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:32:44,863 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:33:44,873 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:34:44,882 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:35:44,889 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:36:44,903 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:37:44,922 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:38:44,931 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:39:44,938 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:40:44,945 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:41:44,953 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:42:44,971 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:43:44,979 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:44:44,986 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:45:44,993 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:46:45,001 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:47:45,014 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:48:45,022 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:49:45,030 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 8 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5127)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1217)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:147)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
2019-10-11 10:50:45,390 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-11 10:50:45,917 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=807&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906&bootstrapstandby=false
2019-10-11 10:50:45,968 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-11 10:50:46,200 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 83.33 KB/s
2019-10-11 10:50:46,200 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000807 size 4185 bytes.
2019-10-11 10:50:46,258 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=808&endTxId=810&storageInfo=-63:1698661175:1570716796840:CID-da841a1a-f6b8-4cac-8191-df1c6f05b906
2019-10-11 10:50:46,301 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2019-10-11 10:50:46,301 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000808-0000000000000000810_0000000000006509517 size 0 bytes.
2019-10-11 10:50:46,371 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 54 INodes.
2019-10-11 10:50:46,405 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-11 10:50:46,405 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 807 from /home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000807
2019-10-11 10:50:46,405 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-11 10:50:46,409 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-11 10:50:46,413 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000808-0000000000000000810 expecting start txid #808
2019-10-11 10:50:46,413 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000808-0000000000000000810
2019-10-11 10:50:46,466 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/luroz/hadoop/store/checkpoint/current/edits_0000000000000000808-0000000000000000810 of size 95 edits # 3 loaded in 0 seconds
2019-10-11 10:50:46,471 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000810 using no compression
2019-10-11 10:50:46,498 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/luroz/hadoop/store/checkpoint/current/fsimage.ckpt_0000000000000000810 of size 967 bytes saved in 0 seconds.
2019-10-11 10:50:46,571 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 807
2019-10-11 10:50:46,571 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000776, cpktTxId=0000000000000000776)
2019-10-11 10:50:46,571 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/luroz/hadoop/store/checkpoint/current/fsimage_0000000000000000806, cpktTxId=0000000000000000806)
2019-10-11 10:50:46,889 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 810 to namenode at http://localhost:50070 in 0.212 seconds
2019-10-11 10:50:46,889 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 967
2019-10-11 11:03:05,620 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-11 11:03:05,622 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-11 11:38:30,016 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-11 11:38:30,023 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-11 11:38:30,366 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-11 11:38:30,467 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-11 11:38:30,521 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-11 11:38:30,521 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-11 11:38:30,644 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-11 11:38:30,645 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-11 11:38:30,684 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-11 11:38:30,740 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 13502@H6
2019-10-11 11:38:30,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-11 11:38:30,749 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-11 11:38:30,751 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-11 11:38:30,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-11 11:38:30,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-11 11:38:30,781 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-11 11:38:30,781 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 11 11:38:30
2019-10-11 11:38:30,782 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-11 11:38:30,782 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-11 11:38:30,783 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-11 11:38:30,783 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-11 11:38:30,795 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-11 11:38:30,798 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-10-11 11:38:30,798 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-11 11:38:30,798 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-11 11:38:30,798 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-11 11:38:30,798 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-11 11:38:30,798 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-11 11:38:30,798 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-11 11:38:30,799 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-11 11:38:30,799 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-11 11:38:30,799 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-11 11:38:30,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-11 11:38:30,802 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-11 11:38:30,851 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-11 11:38:30,851 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-11 11:38:30,851 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-11 11:38:30,851 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-11 11:38:30,851 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-11 11:38:30,851 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-11 11:38:30,852 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-11 11:38:30,857 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-11 11:38:30,857 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-11 11:38:30,858 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-11 11:38:30,858 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-11 11:38:30,859 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-11 11:38:30,859 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-11 11:38:30,859 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-11 11:38:30,862 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-11 11:38:30,862 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-11 11:38:30,862 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-11 11:38:30,884 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-11 11:38:30,885 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-11 11:38:30,893 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-11 11:38:30,938 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-11 11:38:30,945 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-11 11:38:30,951 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-11 11:38:30,956 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-11 11:38:30,958 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-11 11:38:30,958 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-11 11:38:30,958 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-11 11:38:30,971 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-11 11:38:30,971 INFO org.mortbay.log: jetty-6.1.26
2019-10-11 11:38:31,114 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-11 11:38:31,114 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-11 11:39:31,544 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-11 11:39:32,078 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18&bootstrapstandby=false
2019-10-11 11:39:32,154 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-11 11:39:32,447 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 0.00 KB/s
2019-10-11 11:39:32,447 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 322 bytes.
2019-10-11 11:39:32,514 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-11 11:39:32,555 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2019-10-11 11:39:32,556 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000009436903 size 0 bytes.
2019-10-11 11:39:32,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-10-11 11:39:32,646 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-11 11:39:32,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000000
2019-10-11 11:39:32,647 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-11 11:39:32,651 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-11 11:39:32,655 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2019-10-11 11:39:32,655 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000001-0000000000000000002
2019-10-11 11:39:32,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2019-10-11 11:39:32,684 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000002 using no compression
2019-10-11 11:39:32,722 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000002 of size 322 bytes saved in 0 seconds.
2019-10-11 11:39:32,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint
2019-10-11 11:39:32,814 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint
2019-10-11 11:39:33,134 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://localhost:50070 in 0.269 seconds
2019-10-11 11:39:33,134 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 322
2019-10-11 12:39:35,342 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-11 12:39:35,399 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=3&endTxId=62&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-11 12:39:35,497 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 89.29 KB/s
2019-10-11 12:39:35,497 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000062_0000000000013038724 size 0 bytes.
2019-10-11 12:39:35,498 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-11 12:39:35,498 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000003-0000000000000000062 expecting start txid #3
2019-10-11 12:39:35,498 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000003-0000000000000000062
2019-10-11 12:39:35,930 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570808322769_0001/job.jar
2019-10-11 12:39:35,931 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570808322769_0001/job.split
2019-10-11 12:39:35,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000003-0000000000000000062 of size 6059 edits # 60 loaded in 0 seconds
2019-10-11 12:39:35,938 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000062 using no compression
2019-10-11 12:39:35,961 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000062 of size 2165 bytes saved in 0 seconds.
2019-10-11 12:39:35,999 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2019-10-11 12:39:36,000 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-10-11 12:39:36,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 62 to namenode at http://localhost:50070 in 0.148 seconds
2019-10-11 12:39:36,278 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2165
2019-10-11 13:39:20,326 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-10-11 13:39:20,354 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-12 10:58:07,812 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-12 10:58:07,885 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-12 10:58:08,225 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-12 10:58:08,341 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-12 10:58:08,396 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-12 10:58:08,396 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-12 10:58:08,876 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-12 10:58:08,876 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-12 10:58:08,911 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-12 10:58:08,915 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint does not exist
2019-10-12 10:58:08,917 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint is in an inconsistent state: checkpoint directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.recoverCreate(SecondaryNameNode.java:998)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:245)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:194)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:690)
2019-10-12 10:58:08,919 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2019-10-12 10:58:08,920 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-10-12 11:00:23,709 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-10-12 11:00:23,717 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-12 11:00:24,050 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-12 11:00:24,156 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-12 11:00:24,213 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-12 11:00:24,213 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-12 11:00:24,326 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-12 11:00:24,326 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-12 11:00:24,405 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-10-12 11:00:24,470 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 8505@H6
2019-10-12 11:00:24,522 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-10-12 11:00:24,523 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-10-12 11:00:24,525 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-10-12 11:00:24,554 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-12 11:00:24,554 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-12 11:00:24,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-12 11:00:24,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 12 11:00:24
2019-10-12 11:00:24,557 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-12 11:00:24,557 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-12 11:00:24,558 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-12 11:00:24,558 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-12 11:00:24,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-12 11:00:24,572 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-10-12 11:00:24,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-12 11:00:24,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-12 11:00:24,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-12 11:00:24,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-12 11:00:24,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-12 11:00:24,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-12 11:00:24,574 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-10-12 11:00:24,575 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-12 11:00:24,575 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-12 11:00:24,575 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-12 11:00:24,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-12 11:00:24,640 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-12 11:00:24,640 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-12 11:00:24,640 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-12 11:00:24,640 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-12 11:00:24,643 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-10-12 11:00:24,643 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-10-12 11:00:24,643 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-10-12 11:00:24,650 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-12 11:00:24,650 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-12 11:00:24,650 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-12 11:00:24,650 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-12 11:00:24,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-12 11:00:24,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-12 11:00:24,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-12 11:00:24,655 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-10-12 11:00:24,655 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-10-12 11:00:24,655 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-10-12 11:00:24,762 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-10-12 11:00:24,762 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-12 11:00:24,768 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-10-12 11:00:24,814 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-12 11:00:24,821 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-12 11:00:24,825 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-12 11:00:24,830 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-12 11:00:24,832 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-12 11:00:24,832 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-12 11:00:24,832 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-12 11:00:24,845 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-12 11:00:24,845 INFO org.mortbay.log: jetty-6.1.26
2019-10-12 11:00:25,048 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-10-12 11:00:25,048 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-12 11:33:26,449 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-12 11:33:27,202 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=68&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18&bootstrapstandby=false
2019-10-12 11:33:27,325 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-12 11:33:27,738 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 13.16 KB/s
2019-10-12 11:33:27,739 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000068 size 1861 bytes.
2019-10-12 11:33:27,815 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=69&endTxId=120&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 11:33:27,915 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 71.43 KB/s
2019-10-12 11:33:27,915 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000069-0000000000000000120_0000000000003657408 size 0 bytes.
2019-10-12 11:33:28,145 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 23 INodes.
2019-10-12 11:33:28,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-12 11:33:28,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 68 from /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000068
2019-10-12 11:33:28,557 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-12 11:33:28,574 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 11:33:28,578 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000069-0000000000000000120 expecting start txid #69
2019-10-12 11:33:28,579 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000069-0000000000000000120
2019-10-12 11:33:28,916 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570892641171_0001/job.jar
2019-10-12 11:33:28,917 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1570892641171_0001/job.split
2019-10-12 11:33:28,921 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000069-0000000000000000120 of size 5281 edits # 52 loaded in 0 seconds
2019-10-12 11:33:28,963 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000120 using no compression
2019-10-12 11:33:29,043 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000120 of size 2027 bytes saved in 0 seconds.
2019-10-12 11:33:29,119 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 68
2019-10-12 11:33:29,119 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000062, cpktTxId=0000000000000000062)
2019-10-12 11:33:29,120 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2019-10-12 11:33:29,528 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 120 to namenode at http://localhost:50070 in 0.279 seconds
2019-10-12 11:33:29,529 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2027
2019-10-12 12:33:30,513 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 12:33:30,576 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=121&endTxId=122&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 12:33:30,632 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 0.00 KB/s
2019-10-12 12:33:30,632 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000121-0000000000000000122_0000000000007260204 size 0 bytes.
2019-10-12 12:33:30,632 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 12:33:30,632 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000121-0000000000000000122 expecting start txid #121
2019-10-12 12:33:30,633 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000121-0000000000000000122
2019-10-12 12:33:30,633 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000121-0000000000000000122 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 12:33:30,633 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000122 using no compression
2019-10-12 12:33:30,637 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000122 of size 2027 bytes saved in 0 seconds.
2019-10-12 12:33:30,682 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 120
2019-10-12 12:33:30,683 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000068, cpktTxId=0000000000000000068)
2019-10-12 12:33:30,842 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 122 to namenode at http://localhost:50070 in 0.094 seconds
2019-10-12 12:33:30,842 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2027
2019-10-12 13:33:31,973 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 13:33:32,025 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=123&endTxId=124&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 13:33:32,148 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.09s at 0.00 KB/s
2019-10-12 13:33:32,149 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000123-0000000000000000124_0000000000010861653 size 0 bytes.
2019-10-12 13:33:32,149 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 13:33:32,149 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000123-0000000000000000124 expecting start txid #123
2019-10-12 13:33:32,149 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000123-0000000000000000124
2019-10-12 13:33:32,150 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000123-0000000000000000124 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 13:33:32,150 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000124 using no compression
2019-10-12 13:33:32,278 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000124 of size 2027 bytes saved in 0 seconds.
2019-10-12 13:33:32,433 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 122
2019-10-12 13:33:32,433 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000120, cpktTxId=0000000000000000120)
2019-10-12 13:33:32,754 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 124 to namenode at http://localhost:50070 in 0.18 seconds
2019-10-12 13:33:32,754 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2027
2019-10-12 14:33:33,755 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 14:33:33,803 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=125&endTxId=126&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 14:33:33,877 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2019-10-12 14:33:33,877 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000125-0000000000000000126_0000000000014463432 size 0 bytes.
2019-10-12 14:33:33,877 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 14:33:33,877 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000125-0000000000000000126 expecting start txid #125
2019-10-12 14:33:33,877 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000125-0000000000000000126
2019-10-12 14:33:33,878 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000125-0000000000000000126 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 14:33:33,878 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000126 using no compression
2019-10-12 14:33:33,882 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000126 of size 2027 bytes saved in 0 seconds.
2019-10-12 14:33:33,954 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 124
2019-10-12 14:33:33,969 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000122, cpktTxId=0000000000000000122)
2019-10-12 14:33:34,165 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 126 to namenode at http://localhost:50070 in 0.129 seconds
2019-10-12 14:33:34,166 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2027
2019-10-12 15:33:35,005 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 15:33:35,044 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=127&endTxId=128&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 15:33:35,118 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2019-10-12 15:33:35,118 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000127-0000000000000000128_0000000000018064672 size 0 bytes.
2019-10-12 15:33:35,119 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 15:33:35,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000127-0000000000000000128 expecting start txid #127
2019-10-12 15:33:35,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000127-0000000000000000128
2019-10-12 15:33:35,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000127-0000000000000000128 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 15:33:35,120 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000128 using no compression
2019-10-12 15:33:35,124 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000128 of size 2028 bytes saved in 0 seconds.
2019-10-12 15:33:35,178 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 126
2019-10-12 15:33:35,178 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000124, cpktTxId=0000000000000000124)
2019-10-12 15:33:35,396 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 128 to namenode at http://localhost:50070 in 0.145 seconds
2019-10-12 15:33:35,397 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2028
2019-10-12 16:33:36,438 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 16:33:36,484 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=129&endTxId=130&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 16:33:36,634 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2019-10-12 16:33:36,634 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000129-0000000000000000130_0000000000021666112 size 0 bytes.
2019-10-12 16:33:36,635 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 16:33:36,635 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000129-0000000000000000130 expecting start txid #129
2019-10-12 16:33:36,635 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000129-0000000000000000130
2019-10-12 16:33:36,635 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000129-0000000000000000130 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 16:33:36,636 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000130 using no compression
2019-10-12 16:33:36,642 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000130 of size 2028 bytes saved in 0 seconds.
2019-10-12 16:33:36,727 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 128
2019-10-12 16:33:36,727 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000126, cpktTxId=0000000000000000126)
2019-10-12 16:33:37,012 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 130 to namenode at http://localhost:50070 in 0.17 seconds
2019-10-12 16:33:37,012 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2028
2019-10-12 17:33:38,247 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 17:33:38,299 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=131&endTxId=132&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 17:33:38,413 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2019-10-12 17:33:38,432 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000131-0000000000000000132_0000000000025267927 size 0 bytes.
2019-10-12 17:33:38,433 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 17:33:38,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000131-0000000000000000132 expecting start txid #131
2019-10-12 17:33:38,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000131-0000000000000000132
2019-10-12 17:33:38,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000131-0000000000000000132 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 17:33:38,435 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000132 using no compression
2019-10-12 17:33:38,472 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000132 of size 2028 bytes saved in 0 seconds.
2019-10-12 17:33:38,539 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 130
2019-10-12 17:33:38,539 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000128, cpktTxId=0000000000000000128)
2019-10-12 17:33:38,841 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 132 to namenode at http://localhost:50070 in 0.202 seconds
2019-10-12 17:33:38,841 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2028
2019-10-12 18:33:40,148 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 18:33:40,167 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=133&endTxId=134&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 18:33:40,244 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 0.00 KB/s
2019-10-12 18:33:40,244 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000133-0000000000000000134_0000000000028869796 size 0 bytes.
2019-10-12 18:33:40,244 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 18:33:40,244 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000133-0000000000000000134 expecting start txid #133
2019-10-12 18:33:40,244 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000133-0000000000000000134
2019-10-12 18:33:40,263 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000133-0000000000000000134 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 18:33:40,264 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000134 using no compression
2019-10-12 18:33:40,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000134 of size 2028 bytes saved in 0 seconds.
2019-10-12 18:33:40,319 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 132
2019-10-12 18:33:40,319 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000130, cpktTxId=0000000000000000130)
2019-10-12 18:33:40,554 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 134 to namenode at http://localhost:50070 in 0.161 seconds
2019-10-12 18:33:40,554 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2028
2019-10-12 19:33:41,234 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 19:33:41,254 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=135&endTxId=136&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 19:33:41,290 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2019-10-12 19:33:41,290 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000135-0000000000000000136_0000000000032470883 size 0 bytes.
2019-10-12 19:33:41,290 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 19:33:41,290 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000135-0000000000000000136 expecting start txid #135
2019-10-12 19:33:41,290 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000135-0000000000000000136
2019-10-12 19:33:41,290 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000135-0000000000000000136 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 19:33:41,292 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000136 using no compression
2019-10-12 19:33:41,296 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000136 of size 2028 bytes saved in 0 seconds.
2019-10-12 19:33:41,365 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 134
2019-10-12 19:33:41,365 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000132, cpktTxId=0000000000000000132)
2019-10-12 19:33:41,547 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 136 to namenode at http://localhost:50070 in 0.14 seconds
2019-10-12 19:33:41,547 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2028
2019-10-12 20:33:43,810 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 20:33:43,834 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=137&endTxId=138&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 20:33:43,904 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2019-10-12 20:33:43,904 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000137-0000000000000000138_0000000000036073463 size 0 bytes.
2019-10-12 20:33:43,904 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 20:33:43,904 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000137-0000000000000000138 expecting start txid #137
2019-10-12 20:33:43,904 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000137-0000000000000000138
2019-10-12 20:33:43,904 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000137-0000000000000000138 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 20:33:43,905 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000138 using no compression
2019-10-12 20:33:43,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000138 of size 2028 bytes saved in 0 seconds.
2019-10-12 20:33:44,030 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 136
2019-10-12 20:33:44,030 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000134, cpktTxId=0000000000000000134)
2019-10-12 20:33:44,323 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 138 to namenode at http://localhost:50070 in 0.195 seconds
2019-10-12 20:33:44,324 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2028
2019-10-12 21:33:45,142 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 21:33:45,168 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=139&endTxId=140&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 21:33:45,238 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 0.00 KB/s
2019-10-12 21:33:45,238 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000139-0000000000000000140_0000000000039674797 size 0 bytes.
2019-10-12 21:33:45,238 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 21:33:45,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000139-0000000000000000140 expecting start txid #139
2019-10-12 21:33:45,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000139-0000000000000000140
2019-10-12 21:33:45,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000139-0000000000000000140 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 21:33:45,240 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000140 using no compression
2019-10-12 21:33:45,244 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000140 of size 2028 bytes saved in 0 seconds.
2019-10-12 21:33:45,280 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 138
2019-10-12 21:33:45,280 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000136, cpktTxId=0000000000000000136)
2019-10-12 21:33:45,415 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 140 to namenode at http://localhost:50070 in 0.086 seconds
2019-10-12 21:33:45,415 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2028
2019-10-12 22:33:46,157 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 22:33:46,157 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=141&endTxId=142&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 22:33:46,193 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2019-10-12 22:33:46,194 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000141-0000000000000000142_0000000000043275785 size 0 bytes.
2019-10-12 22:33:46,194 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 22:33:46,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000141-0000000000000000142 expecting start txid #141
2019-10-12 22:33:46,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000141-0000000000000000142
2019-10-12 22:33:46,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000141-0000000000000000142 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 22:33:46,201 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000142 using no compression
2019-10-12 22:33:46,204 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000142 of size 2028 bytes saved in 0 seconds.
2019-10-12 22:33:46,286 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 140
2019-10-12 22:33:46,286 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000138, cpktTxId=0000000000000000138)
2019-10-12 22:33:46,429 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 142 to namenode at http://localhost:50070 in 0.11 seconds
2019-10-12 22:33:46,429 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2028
2019-10-12 23:33:47,267 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-12 23:33:47,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=143&endTxId=144&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-10-12 23:33:47,358 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 0.00 KB/s
2019-10-12 23:33:47,358 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000143-0000000000000000144_0000000000046876907 size 0 bytes.
2019-10-12 23:33:47,358 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-12 23:33:47,358 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000143-0000000000000000144 expecting start txid #143
2019-10-12 23:33:47,358 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000143-0000000000000000144
2019-10-12 23:33:47,358 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000143-0000000000000000144 of size 42 edits # 2 loaded in 0 seconds
2019-10-12 23:33:47,359 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000144 using no compression
2019-10-12 23:33:47,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000144 of size 2028 bytes saved in 0 seconds.
2019-10-12 23:33:47,458 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 142
2019-10-12 23:33:47,458 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000140, cpktTxId=0000000000000000140)
2019-10-12 23:33:47,702 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 144 to namenode at http://localhost:50070 in 0.16 seconds
2019-10-12 23:33:47,702 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2028
2019-11-14 18:36:44,966 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-11-14 18:36:45,155 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-11-14 18:36:45,492 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-14 18:36:45,597 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-11-14 18:36:45,654 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-11-14 18:36:45,654 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-11-14 18:36:46,009 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-14 18:36:46,009 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-14 18:36:46,104 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-11-14 18:36:46,322 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 5213@H6
2019-11-14 18:36:46,378 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-11-14 18:36:46,379 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-11-14 18:36:46,381 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-11-14 18:36:46,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-11-14 18:36:46,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-11-14 18:36:46,419 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-11-14 18:36:46,419 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Nov 14 18:36:46
2019-11-14 18:36:46,421 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-11-14 18:36:46,421 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-14 18:36:46,423 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-11-14 18:36:46,423 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-11-14 18:36:46,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-11-14 18:36:46,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-11-14 18:36:46,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-11-14 18:36:46,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-11-14 18:36:46,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-11-14 18:36:46,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-11-14 18:36:46,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-11-14 18:36:46,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-11-14 18:36:46,445 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-11-14 18:36:46,445 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-11-14 18:36:46,445 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-11-14 18:36:46,445 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-11-14 18:36:46,447 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-11-14 18:36:46,497 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-11-14 18:36:46,497 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-14 18:36:46,498 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-11-14 18:36:46,498 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-11-14 18:36:46,500 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-11-14 18:36:46,500 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-11-14 18:36:46,500 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-11-14 18:36:46,507 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-11-14 18:36:46,507 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-14 18:36:46,507 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-11-14 18:36:46,507 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-11-14 18:36:46,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-11-14 18:36:46,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-11-14 18:36:46,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-11-14 18:36:46,512 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-11-14 18:36:46,512 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-11-14 18:36:46,512 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-11-14 18:36:46,538 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-11-14 18:36:46,538 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-11-14 18:36:46,545 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-11-14 18:36:46,604 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-11-14 18:36:46,611 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-14 18:36:46,615 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-11-14 18:36:46,620 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-14 18:36:46,621 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-11-14 18:36:46,622 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-14 18:36:46,622 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-14 18:36:46,634 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-11-14 18:36:46,634 INFO org.mortbay.log: jetty-6.1.26
2019-11-14 18:36:47,056 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-11-14 18:36:47,056 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-11-14 18:37:47,884 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-11-14 18:37:49,156 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=145&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18&bootstrapstandby=false
2019-11-14 18:37:49,287 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-11-14 18:37:50,028 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.21s at 4.76 KB/s
2019-11-14 18:37:50,028 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000145 size 2028 bytes.
2019-11-14 18:37:50,154 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=146&endTxId=147&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-11-14 18:37:50,253 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.10s at 0.00 KB/s
2019-11-14 18:37:50,254 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000146-0000000000000000147_0000000000008167866 size 0 bytes.
2019-11-14 18:37:50,417 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 23 INodes.
2019-11-14 18:37:50,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-11-14 18:37:50,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 145 from /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000145
2019-11-14 18:37:50,556 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-11-14 18:37:50,587 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-14 18:37:50,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000146-0000000000000000147 expecting start txid #146
2019-11-14 18:37:50,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000146-0000000000000000147
2019-11-14 18:37:50,610 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000146-0000000000000000147 of size 42 edits # 2 loaded in 0 seconds
2019-11-14 18:37:50,810 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000147 using no compression
2019-11-14 18:37:51,198 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000147 of size 2028 bytes saved in 0 seconds.
2019-11-14 18:37:51,297 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 145
2019-11-14 18:37:51,297 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000142, cpktTxId=0000000000000000142)
2019-11-14 18:37:51,298 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000144, cpktTxId=0000000000000000144)
2019-11-14 18:37:51,758 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 147 to namenode at http://localhost:50070 in 0.296 seconds
2019-11-14 18:37:51,758 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2028
2019-11-14 19:08:35,530 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-11-14 19:08:37,832 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-11-15 10:54:07,565 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-11-15 10:54:07,596 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-11-15 10:54:07,967 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-15 10:54:08,077 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-11-15 10:54:08,141 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-11-15 10:54:08,141 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-11-15 10:54:08,526 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-15 10:54:08,526 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-15 10:54:08,562 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-11-15 10:54:08,566 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint does not exist
2019-11-15 10:54:08,568 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint is in an inconsistent state: checkpoint directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.recoverCreate(SecondaryNameNode.java:998)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:245)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:194)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:690)
2019-11-15 10:54:08,570 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2019-11-15 10:54:08,573 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-11-15 10:56:17,212 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-11-15 10:56:17,220 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-11-15 10:56:17,557 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-15 10:56:17,659 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-11-15 10:56:17,717 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-11-15 10:56:17,717 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-11-15 10:56:17,820 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-15 10:56:17,820 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-15 10:56:17,855 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-11-15 10:56:17,859 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint does not exist
2019-11-15 10:56:17,860 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint is in an inconsistent state: checkpoint directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.recoverCreate(SecondaryNameNode.java:998)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:245)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:194)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:690)
2019-11-15 10:56:17,862 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2019-11-15 10:56:17,867 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-11-15 11:01:15,757 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-11-15 11:01:15,874 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-11-15 11:01:16,639 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-15 11:01:17,229 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-11-15 11:01:18,557 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-11-15 11:01:18,557 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-11-15 11:01:19,744 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-15 11:01:19,745 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-15 11:01:20,364 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-11-15 11:01:20,555 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 8312@H6
2019-11-15 11:01:20,879 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-11-15 11:01:20,880 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-11-15 11:01:20,882 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-11-15 11:01:21,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-11-15 11:01:21,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-11-15 11:01:21,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-11-15 11:01:21,435 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Nov 15 11:01:21
2019-11-15 11:01:21,445 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-11-15 11:01:21,445 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-15 11:01:21,529 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-11-15 11:01:21,530 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-11-15 11:01:21,600 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-11-15 11:01:21,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-11-15 11:01:21,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-11-15 11:01:21,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-11-15 11:01:21,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-11-15 11:01:21,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-11-15 11:01:21,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-11-15 11:01:21,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-11-15 11:01:21,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-11-15 11:01:21,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-11-15 11:01:21,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-11-15 11:01:21,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-11-15 11:01:21,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-11-15 11:01:22,155 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-11-15 11:01:22,155 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-15 11:01:22,156 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-11-15 11:01:22,156 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-11-15 11:01:22,170 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-11-15 11:01:22,170 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-11-15 11:01:22,171 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-11-15 11:01:22,177 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-11-15 11:01:22,177 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-15 11:01:22,177 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-11-15 11:01:22,177 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-11-15 11:01:22,180 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-11-15 11:01:22,180 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-11-15 11:01:22,180 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-11-15 11:01:22,206 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-11-15 11:01:22,206 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-11-15 11:01:22,206 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-11-15 11:01:22,256 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-11-15 11:01:22,258 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-11-15 11:01:22,302 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-11-15 11:01:22,657 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-11-15 11:01:22,664 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-15 11:01:22,685 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-11-15 11:01:22,690 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-15 11:01:22,692 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-11-15 11:01:22,692 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-15 11:01:22,693 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-15 11:01:22,900 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-11-15 11:01:22,901 INFO org.mortbay.log: jetty-6.1.26
2019-11-15 11:01:23,731 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-11-15 11:01:23,734 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-11-15 11:42:28,017 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-11-15 11:42:29,702 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=149&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18&bootstrapstandby=false
2019-11-15 11:42:29,879 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-11-15 11:42:30,246 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.09s at 10.75 KB/s
2019-11-15 11:42:30,246 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000149 size 2028 bytes.
2019-11-15 11:42:30,314 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=150&endTxId=157&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-11-15 11:42:30,388 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 0.00 KB/s
2019-11-15 11:42:30,388 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000150-0000000000000000157_0000000000003643949 size 0 bytes.
2019-11-15 11:42:31,217 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 23 INodes.
2019-11-15 11:42:31,857 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 1 seconds.
2019-11-15 11:42:31,857 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 149 from /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000149
2019-11-15 11:42:31,862 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-11-15 11:42:31,964 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-15 11:42:32,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000150-0000000000000000157 expecting start txid #150
2019-11-15 11:42:32,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000150-0000000000000000157
2019-11-15 11:42:32,498 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000150-0000000000000000157 of size 544 edits # 8 loaded in 0 seconds
2019-11-15 11:42:32,542 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000157 using no compression
2019-11-15 11:42:32,735 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000157 of size 2096 bytes saved in 0 seconds.
2019-11-15 11:42:32,856 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 149
2019-11-15 11:42:32,856 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000147, cpktTxId=0000000000000000147)
2019-11-15 11:42:32,856 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000145, cpktTxId=0000000000000000145)
2019-11-15 11:42:33,427 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 157 to namenode at http://localhost:50070 in 0.373 seconds
2019-11-15 11:42:33,427 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2096
2019-11-15 12:42:40,941 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-15 12:42:40,967 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=158&endTxId=227&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-11-15 12:42:41,112 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 175.00 KB/s
2019-11-15 12:42:41,113 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000158-0000000000000000227_0000000000007253930 size 0 bytes.
2019-11-15 12:42:41,113 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-15 12:42:41,113 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000158-0000000000000000227 expecting start txid #158
2019-11-15 12:42:41,113 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000158-0000000000000000227
2019-11-15 12:42:41,176 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1573829793786_0001/job.jar
2019-11-15 12:42:41,185 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1573829793786_0001/job.split
2019-11-15 12:42:41,189 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1573829793786_0002/job.jar
2019-11-15 12:42:41,190 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1573829793786_0002/job.split
2019-11-15 12:42:41,191 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000158-0000000000000000227 of size 7468 edits # 70 loaded in 0 seconds
2019-11-15 12:42:41,192 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000227 using no compression
2019-11-15 12:42:41,197 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000227 of size 3173 bytes saved in 0 seconds.
2019-11-15 12:42:41,238 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 157
2019-11-15 12:42:41,238 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000149, cpktTxId=0000000000000000149)
2019-11-15 12:42:42,218 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 227 to namenode at http://localhost:50070 in 0.88 seconds
2019-11-15 12:42:42,218 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 3173
2019-11-15 13:37:50,918 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-11-15 13:37:50,952 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-11-15 13:37:51,283 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-15 13:37:51,395 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-11-15 13:37:51,455 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-11-15 13:37:51,455 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-11-15 13:37:51,806 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-15 13:37:51,806 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-15 13:37:51,839 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-11-15 13:37:51,843 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint does not exist
2019-11-15 13:37:51,845 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint is in an inconsistent state: checkpoint directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.recoverCreate(SecondaryNameNode.java:998)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:245)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:194)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:690)
2019-11-15 13:37:51,847 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2019-11-15 13:37:51,848 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at H6/127.0.1.1
************************************************************/
2019-11-15 13:38:45,885 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = luroz
STARTUP_MSG:   host = H6/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.5
STARTUP_MSG:   classpath = /home/luroz/hadoop/etc/hadoop:/home/luroz/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/luroz/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/luroz/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/luroz/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/common/hadoop-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs:/home/luroz/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.5.jar:/home/luroz/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/luroz/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5-tests.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.5.jar:/home/luroz/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 0b8464d75227fcee2c6e7f2410377b3d53d3d5f8; compiled by 'jdu' on 2018-09-10T03:32Z
STARTUP_MSG:   java = 1.8.0_222
************************************************************/
2019-11-15 13:38:45,892 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-11-15 13:38:46,238 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-15 13:38:46,338 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-11-15 13:38:46,396 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-11-15 13:38:46,396 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-11-15 13:38:46,497 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-15 13:38:46,498 WARN org.apache.hadoop.hdfs.server.common.Util: Path /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-15 13:38:46,537 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-11-15 13:38:46,640 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/in_use.lock acquired by nodename 4362@H6
2019-11-15 13:38:46,689 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-11-15 13:38:46,690 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-11-15 13:38:46,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-11-15 13:38:46,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-11-15 13:38:46,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-11-15 13:38:46,721 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-11-15 13:38:46,721 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Nov 15 13:38:46
2019-11-15 13:38:46,722 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-11-15 13:38:46,723 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-15 13:38:46,724 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-11-15 13:38:46,724 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-11-15 13:38:46,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-11-15 13:38:46,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2019-11-15 13:38:46,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-11-15 13:38:46,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-11-15 13:38:46,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-11-15 13:38:46,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-11-15 13:38:46,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-11-15 13:38:46,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-11-15 13:38:46,740 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = luroz (auth:SIMPLE)
2019-11-15 13:38:46,740 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-11-15 13:38:46,740 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-11-15 13:38:46,740 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-11-15 13:38:46,742 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-11-15 13:38:46,790 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-11-15 13:38:46,790 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-15 13:38:46,790 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-11-15 13:38:46,791 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-11-15 13:38:46,792 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-11-15 13:38:46,792 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-11-15 13:38:46,793 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-11-15 13:38:46,799 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-11-15 13:38:46,799 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-15 13:38:46,799 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-11-15 13:38:46,799 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-11-15 13:38:46,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-11-15 13:38:46,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-11-15 13:38:46,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-11-15 13:38:46,803 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-11-15 13:38:46,803 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-11-15 13:38:46,803 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-11-15 13:38:46,853 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-11-15 13:38:46,853 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-11-15 13:38:46,860 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2019-11-15 13:38:46,904 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-11-15 13:38:46,911 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-15 13:38:46,915 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-11-15 13:38:46,920 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-15 13:38:46,921 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-11-15 13:38:46,921 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-15 13:38:46,921 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-15 13:38:46,933 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-11-15 13:38:46,933 INFO org.mortbay.log: jetty-6.1.26
2019-11-15 13:38:47,031 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2019-11-15 13:38:47,031 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-11-15 14:34:48,938 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-11-15 14:34:50,288 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=227&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18&bootstrapstandby=false
2019-11-15 14:34:50,450 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-11-15 14:34:50,834 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.09s at 34.88 KB/s
2019-11-15 14:34:50,834 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000227 size 3173 bytes.
2019-11-15 14:34:50,910 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=228&endTxId=228&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-11-15 14:34:51,009 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 13837.84 KB/s
2019-11-15 14:34:51,009 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000228-0000000000000000228_0000000000003657618 size 0 bytes.
2019-11-15 14:34:51,010 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=229&endTxId=269&storageInfo=-63:987000046:1570808272446:CID-00e7d5f5-8518-44e1-9fc7-410b8b1bfa18
2019-11-15 14:34:51,084 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 55.56 KB/s
2019-11-15 14:34:51,084 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000229-0000000000000000269_0000000000003657719 size 0 bytes.
2019-11-15 14:34:51,379 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 39 INodes.
2019-11-15 14:34:51,755 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-11-15 14:34:51,755 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 227 from /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000227
2019-11-15 14:34:51,756 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-11-15 14:34:51,762 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-11-15 14:34:51,765 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000228-0000000000000000228 expecting start txid #228
2019-11-15 14:34:51,766 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000228-0000000000000000228
2019-11-15 14:34:51,805 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000228-0000000000000000228 of size 1048576 edits # 1 loaded in 0 seconds
2019-11-15 14:34:51,806 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000229-0000000000000000269 expecting start txid #229
2019-11-15 14:34:51,806 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000229-0000000000000000269
2019-11-15 14:34:51,911 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1573839552933_0001/job.jar
2019-11-15 14:34:51,913 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/luroz/.staging/job_1573839552933_0001/job.split
2019-11-15 14:34:51,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/edits_0000000000000000229-0000000000000000269 of size 4283 edits # 41 loaded in 0 seconds
2019-11-15 14:34:51,947 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000269 using no compression
2019-11-15 14:34:52,011 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage.ckpt_0000000000000000269 of size 4042 bytes saved in 0 seconds.
2019-11-15 14:34:52,091 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 227
2019-11-15 14:34:52,092 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/media/luroz/b00b357b-1dac-4b88-98fa-3f2cd80fa803/luroz/hadoop/checkpoint/current/fsimage_0000000000000000157, cpktTxId=0000000000000000157)
2019-11-15 14:34:52,407 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 269 to namenode at http://localhost:50070 in 0.231 seconds
2019-11-15 14:34:52,408 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4042
